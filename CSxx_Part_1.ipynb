{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRiNtQlSQEbT"
      },
      "source": [
        "## Overview and Abstract\n",
        "\n",
        "\n",
        "\n",
        "**Team J**\n",
        "\n",
        "\n",
        "# Task overview\n",
        "\n",
        "The dataset provided for CS98-DL-Task1 Relevance Modelling contains entries of search results returned by a procurement search engine during a userâ€™s search session. The aim of our task was to decide whether each document is relevant or not by creating a binary classifier model.\n",
        "\n",
        "In order to solve the problem at hand, we have implemented three different models. The first one was a standard machine learning base line model for which we have chosen to user a Gradient Boosting Classifier. The second one was a simple deep learning neural network with 3 hidden layers, the results of which were used for performance comparison with a more sophisticated deep learning model. The last model we have built was a Recurrent Neural Network, with LSTM hidden layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "m2e4BV6pqn1D",
        "outputId": "c49abbab-1919-413c-83a5-a974536adbef"
      },
      "source": [
        "#Imports and seed specification\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import tempfile\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import random as rn\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from google.colab import files \n",
        "from sklearn.ensemble import  GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate\n",
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "SEED = 23\n",
        "os.environ['PYTHONHASHSEED']=str(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "rn.seed(SEED)\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c3a3f5dd-9080-4c94-aefa-b61340585e0d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c3a3f5dd-9080-4c94-aefa-b61340585e0d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJS3BvX-QE-u"
      },
      "source": [
        "# Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9VYKe2QAQux"
      },
      "source": [
        "##Data Processing and Feature Extraction\n",
        "\n",
        "The process of tackling the problem began with a thorough exploration of the features in the dataset folllowed by data preprocessing. The dataset is relatively small with 33,000 entries and 19 columns containing both numerical and textual data. All columns except the 'nature' column did not contain empty values which can be problematic for the models to deal with. Due to the limited data provided, a decision was made to fill the missing entries with the neutral value 'Other' rather than dropping them. Furthermore, the values in the 'psrel' columns, which contains the labels for the training of the binary classifiers, were found to be highly imbalanced with only 5.95% of the values belonging to the positive class. This is likely to result in the poor performance of the models in their predictions for the minority class and thus prevent us from achieving reasonable results. The severe imbalance in the class distributions of the dataset implies that some sort of a data augmentation technique has to be employed. One common approach to addressing such issues is to use an algorithm to oversample the minority class. Rather than just duplicating entries of the minority group, a better approach is to synthesize new data from the existing examples. This type of data augmentation is generally referred to as 'Synthetic Minority Oversampling Technique', or SMOTE for short, and it was utilized in this task. After employing the SMOTE implementation from the imblearn library on the training dataset, the number of entries was increased in favour of the positive class resulting in a 50:50 distribution. **[1]**\n",
        "In addition,  a decision was made to drop some of the columns which did not contain relevant information that can be used to classify the documents - 'user', 'session', 'query', 'timestamp','cpvs'. The main reasoning behind this decision is that those columns contained different identifiers with regards to the query, but since their values are almost always unique they do not really contain that much useful information for the training process. Nevertheless, a more sophisticated solution could have been employed which ideally could have established a relationship between the session and user identifiers since some of the entries overlap in their values for these columns. What's more, the remaning columns which contained categorical data were one-hot encoded before they were fed into the models. The final stage of the preprocessing was to scale the data using sklearn's StandardScaler in order to improve the learning process further, especially for the standard machine learning model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEzR-ctUAV-f"
      },
      "source": [
        "##Baseline Machine Learning Model\n",
        "In terms of model, a standard machine learning solution had to be created to serve as a baseline for the other models. A decision was made to utilize an ensemble machine learning model, which usually provide better performance and generalization to more simplistic models. The classifier selected for the task was the GradientBoostingClassifier (GBC). This classifier combines multiple weak learning models (decision trees) in order to create a strong predictive model capable of handling complex datasets. In recent years GBC models are becoming more popular due to their effectiveness and such models have been winning scientific Kaggle competitions quite frequently. **[2]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiS0V6TIAa9G"
      },
      "source": [
        "##Neural Network Models\n",
        "As for the neural models developed, two such models were creating which differ in their architecture and complexity in order to test the effectiveness of each approach. Firstly, a baseline neural network model with three hidden layers was developed. Since this model was to be used as a base for comparison, neither regularization techniques such as regularizers and dropouts, nor more complex initialization schemes for the weighs were used in its specification. The architecture of the model is sequential/feedforward and it  consists of an input layer, which expects an input shape with 44 features (the total number of features after the one hot encoding of the data). Then, this layer is followed by three hidden Dense layers with a \"relu\" activation function and equal number of neurons. Finally, the output layer of this model has only one neuron and a sigmoid activation function, which makes it suitable for the binary classification task. The sigmoid function returns a value between 0 and 1 which makes it straight-forward to interpret the output as either belonging to the positive or negative class - values below 0.5 belong to the negative class, while values above 0.5 can be interpreted as part of the positive one.\n",
        "\n",
        "In order to test the performance on the dataset of a neural network with a different and more compltex architecture, an Recurrent Neural Network(RNN) model was designed. Generally , such models are usually employed to tackle problems involing sequential or time-series data due to their ability to capture information about what has been calculated so far in more complex memory cells in comparison to the normal neurons. Usually, RNNS are used for compltex tasks with sequential data  such as language translation, speech recognition, natural language processing.**[3]** Nevertheless, they have proven to be effective in finding solutions for binary classification issues as well, which is the reason why a model with such architecture was developed and evaluated. The model that was created consists of a series of N RNN layers with LSTM memory cells, each followed by a dropout layer that would help the model to generalise better and not overfit the data. Since the RNN expects a 3 dimensional array of training data, another version of the data reshaped in the format (Number of samples, Sequence length, Input dimensions). Similarly to the basic neural network model, the final output layer has one neuron with a sigmoid activation function for binary classificaiton. The class definitions for both neural network models are presented in the code snippet below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ir46jBC3500"
      },
      "source": [
        "#Class definition of the Baseline Deep Learning Model\n",
        "class BaselineDeepLearningModel(keras.Model):\n",
        "  def __init__(self, n_neurons=30, input_shape = [44,] ,activation = \"relu\",  **kwargs):\n",
        "    super().__init__( **kwargs)\n",
        "    #self.input_layer = keras.layers.Flatten(input_shape = input_shape)\n",
        "    self.hidden1 = keras.layers.Dense(n_neurons, activation=activation)\n",
        "    self.hidden2 = keras.layers.Dense(n_neurons, activation=activation)\n",
        "    self.hidden3 = keras.layers.Dense(n_neurons, activation=activation)\n",
        "    self.output_layer = keras.layers.Dense(1, activation = \"sigmoid\")\n",
        "\n",
        "  def call(self, inputs):\n",
        "    #input_layer = self.input_layer(inputs)\n",
        "    hidden1 = self.hidden1(inputs)\n",
        "    hidden2 = self.hidden2(hidden1)\n",
        "    hidden3 = self.hidden3(hidden2)\n",
        "    output_layer = self.output_layer(hidden3)\n",
        "    return output_layer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8nTzZQWcELX"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#Class definition of the RNN Deep Learning Model\n",
        "class RNNModel(keras.Model):\n",
        "  def __init__(self, n_neurons=30, dropout = 0.2, input_shape = [1,44], activation = \"relu\",  **kwargs):\n",
        "    super().__init__( **kwargs)\n",
        "    self.lstm1 = keras.layers.LSTM(n_neurons, kernel_initializer = keras.initializers.he_normal(seed=SEED), return_sequences = True)\n",
        "    self.dropout1 = keras.layers.Dropout(dropout)\n",
        "    self.lstm2 = keras.layers.LSTM(n_neurons, kernel_initializer = keras.initializers.he_normal(seed=SEED), return_sequences = True)\n",
        "    self.dropout2 = keras.layers.Dropout(dropout)\n",
        "    self.lstm3 = keras.layers.LSTM(n_neurons, kernel_initializer = keras.initializers.he_normal(seed=SEED), return_sequences = True)\n",
        "    self.dropout3 = keras.layers.Dropout(dropout)\n",
        "    self.lstm4 = keras.layers.LSTM(n_neurons, kernel_initializer = keras.initializers.he_normal(seed=SEED), return_sequences = True)\n",
        "    self.dropout4 = keras.layers.Dropout(dropout)\n",
        "    self.lstm5 = keras.layers.LSTM(n_neurons, kernel_initializer = keras.initializers.he_normal(seed=SEED), return_sequences = True)\n",
        "    self.dropout5 = keras.layers.Dropout(dropout)\n",
        "    self.lstm6 = keras.layers.LSTM(n_neurons, kernel_initializer = keras.initializers.he_normal(seed=SEED), return_sequences = True)\n",
        "    self.dropout6 = keras.layers.Dropout(dropout)\n",
        "    self.lstm7 = keras.layers.LSTM(n_neurons, kernel_initializer = keras.initializers.he_normal(seed=SEED))\n",
        "    self.output_layer = keras.layers.Dense(1, activation = \"sigmoid\")\n",
        "\n",
        "  def call(self, inputs):\n",
        "    lstm1 = self.lstm1(inputs)\n",
        "    dropout1 = self.dropout1(lstm1)\n",
        "    lstm2 = self.lstm2(dropout1)\n",
        "    dropout2 = self.dropout2(lstm2)\n",
        "    lstm3 = self.lstm3(dropout2)\n",
        "    dropout3 = self.dropout3(lstm3)\n",
        "    lstm4 = self.lstm4(dropout3)\n",
        "    dropout4 = self.dropout4(lstm4)\n",
        "    lstm5 = self.lstm5(dropout4)\n",
        "    dropout5 = self.dropout5(lstm5)\n",
        "    lstm6 = self.lstm6(dropout5)\n",
        "    dropout6 = self.dropout6(lstm6)\n",
        "    lstm7 = self.lstm7(dropout6)\n",
        "    output_layer = self.output_layer(lstm7)\n",
        "    return output_layer\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2QgG5RNAeyf"
      },
      "source": [
        "##Training Schedule Approach\n",
        "In order to achieve the best results possible, the configurations possible for the neural network, the optimal hidden layers and number of neurons had to be explored. For each of two models, a builder function was created and it was provided as a parameter to the KerasClassifier wrapper class. This wrapper was then used in the initialization of a RandomizedSearchCV along with a dictionary of the parameters that are to be explored. The RandomizedSearchCv class then runs a grid search based on the paramters value pairs provided and saves the result at each iteration. Finally, the best performing parameters can be obtained once the search is finished. Due to the limited GPU power and time provided in Google Collab, the space of values that was explored was fairly limited. The builder code for the builder functions for each of the deep learning models is shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25eYQMBzeueR"
      },
      "source": [
        "#Definition of the metrics to be used when compiling deep learning models.\n",
        "metrics = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMc_jnxf2p7t"
      },
      "source": [
        "def build_model_basic(n_hidden=3, n_neurons=30, learning_rate=3e-3, input_shape=[44,]):\n",
        "\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=input_shape))\n",
        "  for layer in range(n_hidden):\n",
        "    model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "  model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
        "  \n",
        "  model.compile(optimizer=  keras.optimizers.Adam(lr=learning_rate),\n",
        "                loss = keras.losses.BinaryCrossentropy(),\n",
        "                metrics = metrics)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uVRbg9FECGU"
      },
      "source": [
        "def build_RNN_model(n_hidden=6, n_neurons=30, droupout = 0.2, input_shape=[1,44], learning_rate=0.01):\n",
        "\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(keras.layers.LSTM(200,input_shape=input_shape, return_sequences = True))\n",
        "  for layer in range(n_hidden):\n",
        "    model.add(keras.layers.LSTM(n_neurons, kernel_initializer = keras.initializers.he_normal(seed=SEED), return_sequences = True))\n",
        "    model.add(keras.layers.Dropout(droupout))\n",
        "  model.add(keras.layers.LSTM(n_neurons, kernel_initializer = keras.initializers.he_normal(seed=SEED)))\n",
        "  model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
        "  \n",
        "  model.compile(optimizer = keras.optimizers.Adam(lr=learning_rate),\n",
        "                loss = keras.losses.BinaryCrossentropy(),\n",
        "                metrics = metrics)\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMHD2Bg-AkS-"
      },
      "source": [
        "- Describe any other things that you did or tried in order to improve performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G-NyuSQQFW4"
      },
      "source": [
        "# Results and Discussion\n",
        "\n",
        "**Parameters setttings for each approarch:**\n",
        "\n",
        "Gradient Boosting Classifier model:\n",
        "*   n_estimators = 10   \n",
        "*   max_depth = 5\n",
        "*   learning_rate = 1.0\n",
        "\n",
        "Paramteres for the Base Dense Deep Learning Network:\n",
        "*   Adam optimization with 0.01 learning rate\n",
        "*   Hidden Dense Layers = 3\n",
        "*   Dense Layer Neurons = 54\n",
        "*   Activation = ReLU\n",
        "\n",
        "The parameters used for RNN Neural Network were:\n",
        "*   Adam optimization with 0.001 learning rate\n",
        "*   GRU Layers = 3\n",
        "*   GRU hidden state neurons = 200\n",
        "*   Dropout rate = 0.5\n",
        "---\n",
        "\n",
        "\n",
        "The best performing model was the GBC model without data augmentation, then our basic model without data augmentation, followed by the basic model with data augmentation. The RNN model heavily overfitted the data when it was trained with no data augmentation. However, when trained with the oversampled data it performed nearly as good as the Basic Model. Overall, the data augmentation prooved quite successfull approach when used with the RNN network but it had negative impact on the GBC and the Basic Model. It might be a good idea to explore other data augmentation techniques for handling imbalanced datasets, for example the undersample approach can be used.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "3zVyJY1Bv8Ri",
        "outputId": "a966261f-0ccd-4e8f-aeaa-87dbe45722a3"
      },
      "source": [
        "d = {'Model': [\"Gradient Boosting Classifier [Data Augmentation]\", \"Gradient Boosting Classifier [No Data Augmentation]\", \"Basic Deep Learning Model [Data Augmentation]\", \"Basic Deep Learning Model [No Data Augmentation]\", \"RNN LSTM Deep Learning Model [Data Augmentation]\", \"RNN LSTM Deep Learning Model [No Data Augmentation]\"], 'Training F1 Score': [0.98, 0.68, 0.42, 0.45, 0.37, 0.73], 'Kaggle Score': [0.074, 0.113, 0.073, 0.084, 0.065, 0.00]}\n",
        "df = pd.DataFrame(data=d)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Training F1 Score</th>\n",
              "      <th>Kaggle Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gradient Boosting Classifier [Data Augmentation]</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gradient Boosting Classifier [No Data Augmenta...</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Basic Deep Learning Model [Data Augmentation]</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basic Deep Learning Model [No Data Augmentation]</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RNN LSTM Deep Learning Model [Data Augmentation]</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RNN LSTM Deep Learning Model [No Data Augmenta...</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Model  ...  Kaggle Score\n",
              "0   Gradient Boosting Classifier [Data Augmentation]  ...         0.074\n",
              "1  Gradient Boosting Classifier [No Data Augmenta...  ...         0.113\n",
              "2      Basic Deep Learning Model [Data Augmentation]  ...         0.073\n",
              "3   Basic Deep Learning Model [No Data Augmentation]  ...         0.084\n",
              "4   RNN LSTM Deep Learning Model [Data Augmentation]  ...         0.065\n",
              "5  RNN LSTM Deep Learning Model [No Data Augmenta...  ...         0.000\n",
              "\n",
              "[6 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHtixmddRSAQ"
      },
      "source": [
        "# Summary and Recommendation\n",
        "\n",
        "In conclusion, to our surprise the standard machine learning outperformed the deep learning models that were created due to its ability to generalise better. Nevertheless, exploring the possibility of creating a more sophisticated deep learning model which combines more advanced techniques that are out of the scope of this course can be very beneficial as it is likely to produce even better results.\n",
        "\n",
        "- Provide a recommendation of which approach(s) should be used/considered and the proâ€™s and conâ€™s of the approach. i.e. should the company use a particular model, and if so what are the caveats?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Qh9x2K_RW_P"
      },
      "source": [
        "# References\n",
        "\n",
        "**[1]** Brownlee J., 2021, 'SMOTE for Imbalanced Classification with Python', *Machine Learning Mastery*,   Source: \n",
        "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/ (Last accessed 11/04/2021)\n",
        "\n",
        "\n",
        "\n",
        "**[2]** Nelson D., 2021, 'Gradient Boosting Classifiers in Python with Scikit-Learn', *Stack Abuse*,   Source: \n",
        "https://stackabuse.com/gradient-boosting-classifiers-in-python-with-scikit-learn/ (Last accessed 11/04/2021)\n",
        "\n",
        "\n",
        "**[3]**  'Recurrent Neural Networks', *IBM*,   Source: \n",
        "https://www.ibm.com/cloud/learn/recurrent-neural-networks  (Last accessed 11/04/2021)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BayFFk0CW-u6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXtZ3k88RZ9o"
      },
      "source": [
        "# Code\n",
        "\n",
        "Feature Processing\n",
        "- Report how your processed the data here or in a separate notebook (provide link if a separate notebook is used).\n",
        "\n",
        "Training and Validating etc.\n",
        "- Show your working here â€“ where you report all your training and validation, etc. that you performed in order to get the results.\n",
        "- Note that it is important that you results can be replicated. All code to reproduce the final predictions must be included, along with any code that justifies your choices.\n",
        "\n",
        "Any Additional Analysis\n",
        "- Add in any additional analysis etc that you performed here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux63QeN984hH",
        "outputId": "eda10e90-4d28-4ba2-dcc7-91d571ea6826"
      },
      "source": [
        "# To get it to work you need to install the lower verison 0.21.2\n",
        "# un coment, install, and then restart\n",
        "\n",
        "!pip install scikit-learn==0.21.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.7/dist-packages (0.21.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.2) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.2) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "lHInI0uqqzK2",
        "outputId": "5479814b-44f5-4c08-e8a5-0a41df9a2550"
      },
      "source": [
        "test_df = pd.read_csv('test.csv')\n",
        "x_test_Id = test_df.pop(\"Id\")\n",
        "train_df = pd.read_csv('train.csv')\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>session</th>\n",
              "      <th>query</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>search</th>\n",
              "      <th>rank</th>\n",
              "      <th>serp</th>\n",
              "      <th>hour</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>dwell</th>\n",
              "      <th>new-sub</th>\n",
              "      <th>premium-pack</th>\n",
              "      <th>psrel</th>\n",
              "      <th>source</th>\n",
              "      <th>type</th>\n",
              "      <th>nature</th>\n",
              "      <th>cpvs</th>\n",
              "      <th>#cpv45</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8438057</td>\n",
              "      <td>A311E564F0A79803FB564CEAB6D7499A</td>\n",
              "      <td>d4fe169251f77f0800245e2df8376856</td>\n",
              "      <td>2020-05-26 10:45:36</td>\n",
              "      <td>quick</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>Tue</td>\n",
              "      <td>May</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Intercon</td>\n",
              "      <td>notice</td>\n",
              "      <td>services</td>\n",
              "      <td>['66131100', '66141000', '66519600', '66520000']</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8438876</td>\n",
              "      <td>5E91CF19B8BEBA58A90E54EC97AAB3AF</td>\n",
              "      <td>5066bca0a00273cf3925b0c2f260f763</td>\n",
              "      <td>2020-01-21 10:47:51</td>\n",
              "      <td>saved</td>\n",
              "      <td>75</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>Tue</td>\n",
              "      <td>Jan</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Contrax Weekly</td>\n",
              "      <td>notice</td>\n",
              "      <td>services</td>\n",
              "      <td>['79421000', '92520000', '92521000']</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>922102585</td>\n",
              "      <td>7D717BA805FB42D51D6C8EC15C0DE2C1</td>\n",
              "      <td>174e0e6c62fd5d7b044dd05b47ce79c9</td>\n",
              "      <td>2020-02-05 09:37:42</td>\n",
              "      <td>advanced</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>Wed</td>\n",
              "      <td>Feb</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Contrax Weekly</td>\n",
              "      <td>notice</td>\n",
              "      <td>services</td>\n",
              "      <td>['79421000', '92520000', '92521000']</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2105483652</td>\n",
              "      <td>D4855E55686DB80328B141598E3174CE</td>\n",
              "      <td>0f9f7f67dc569a6e3dba1ef35ce8970a</td>\n",
              "      <td>2020-01-21 14:43:57</td>\n",
              "      <td>advanced</td>\n",
              "      <td>66</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>Tue</td>\n",
              "      <td>Jan</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Contrax Weekly</td>\n",
              "      <td>notice</td>\n",
              "      <td>services</td>\n",
              "      <td>['79421000', '92520000', '92521000']</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8438876</td>\n",
              "      <td>5E91CF19B8BEBA58A90E54EC97AAB3AF</td>\n",
              "      <td>5066bca0a00273cf3925b0c2f260f763</td>\n",
              "      <td>2020-01-21 10:48:33</td>\n",
              "      <td>saved</td>\n",
              "      <td>81</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Tue</td>\n",
              "      <td>Jan</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Contrax Weekly</td>\n",
              "      <td>notice</td>\n",
              "      <td>services</td>\n",
              "      <td>['72000000', '72263000', '72300000']</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         user  ... #cpv45\n",
              "0     8438057  ...      1\n",
              "1     8438876  ...      2\n",
              "2   922102585  ...      2\n",
              "3  2105483652  ...      2\n",
              "4     8438876  ...      1\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sZOe9XrBh-P",
        "outputId": "ffd0343b-aefe-437d-9c26-7a1721d6aebe"
      },
      "source": [
        "train_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 33000 entries, 0 to 32999\n",
            "Data columns (total 19 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   user          33000 non-null  int64 \n",
            " 1   session       33000 non-null  object\n",
            " 2   query         33000 non-null  object\n",
            " 3   timestamp     33000 non-null  object\n",
            " 4   search        33000 non-null  object\n",
            " 5   rank          33000 non-null  int64 \n",
            " 6   serp          33000 non-null  int64 \n",
            " 7   hour          33000 non-null  int64 \n",
            " 8   day           33000 non-null  object\n",
            " 9   month         33000 non-null  object\n",
            " 10  dwell         33000 non-null  int64 \n",
            " 11  new-sub       33000 non-null  int64 \n",
            " 12  premium-pack  33000 non-null  int64 \n",
            " 13  psrel         33000 non-null  int64 \n",
            " 14  source        33000 non-null  object\n",
            " 15  type          33000 non-null  object\n",
            " 16  nature        21598 non-null  object\n",
            " 17  cpvs          33000 non-null  object\n",
            " 18  #cpv45        33000 non-null  int64 \n",
            "dtypes: int64(9), object(10)\n",
            "memory usage: 4.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ86L02LcHvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f4977f-9cd2-43d7-f240-bffde5d7cd39"
      },
      "source": [
        "train_df.nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user             1171\n",
              "session          8196\n",
              "query           12906\n",
              "timestamp       32610\n",
              "search              4\n",
              "rank              623\n",
              "serp               78\n",
              "hour               24\n",
              "day                 7\n",
              "month               6\n",
              "dwell            1205\n",
              "new-sub             2\n",
              "premium-pack        2\n",
              "psrel               2\n",
              "source             12\n",
              "type                4\n",
              "nature              3\n",
              "cpvs             9441\n",
              "#cpv45             24\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_L9mxQhcJEY"
      },
      "source": [
        "plt.figure(figsize = (6,5))\n",
        "sns.heatmap(train_df.corr(method = \"kendall\"), annot = True, fmt = \".1g\", vmin = -1, vmax =1, center =0,cmap=\"coolwarm\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5AluXHdq4y-",
        "outputId": "9c5857d8-82c7-4994-fec8-d245006d6ce7"
      },
      "source": [
        "neg, pos = np.bincount(train_df['psrel'])\n",
        "total = neg + pos\n",
        "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, pos, 100 * pos / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Examples:\n",
            "    Total: 33000\n",
            "    Positive: 1962 (5.95% of total)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EozPQaWzq64i"
      },
      "source": [
        "cleaned_train_df = train_df.copy()\n",
        "# You don't want the `Time` column.\n",
        "cleaned_train_df.drop(columns=['user', 'session', 'query', 'timestamp','cpvs'], inplace=True)\n",
        "\n",
        "cleaned_train_df.fillna(\"Other\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ACbFh32vQOi"
      },
      "source": [
        "#Train DataFrame encoding\n",
        "le = preprocessing.LabelEncoder()\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "enc.fit(cleaned_train_df['search'].to_numpy().reshape(-1, 1))\n",
        "search_onehot = enc.transform(cleaned_train_df['search'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Make the 2d array a pandas series\n",
        "ohe_df = pd.DataFrame(search_onehot, columns=enc.get_feature_names())\n",
        "\n",
        "cleaned_train_df = cleaned_train_df.drop(['search'], axis=1)\n",
        "cleaned_train_df = cleaned_train_df.reset_index(drop=True)\n",
        "cleaned_train_df = pd.concat([cleaned_train_df, ohe_df], axis=1)\n",
        "\n",
        "\n",
        "enc.fit(cleaned_train_df['source'].to_numpy().reshape(-1, 1))\n",
        "source_onehot = enc.transform(cleaned_train_df['source'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Make the 2d array a pandas series\n",
        "ohe_df = pd.DataFrame(source_onehot, columns=enc.get_feature_names())\n",
        "\n",
        "cleaned_train_df = cleaned_train_df.drop(['source'], axis=1)\n",
        "cleaned_train_df = cleaned_train_df.reset_index(drop=True)\n",
        "cleaned_train_df = pd.concat([cleaned_train_df, ohe_df], axis=1)\n",
        "\n",
        "enc.fit(cleaned_train_df['day'].to_numpy().reshape(-1, 1))\n",
        "day_onehot = enc.transform(cleaned_train_df['day'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Make the 2d array a pandas series\n",
        "ohe_df = pd.DataFrame(day_onehot, columns=enc.get_feature_names())\n",
        "\n",
        "cleaned_train_df = cleaned_train_df.drop(['day'], axis=1)\n",
        "cleaned_train_df = cleaned_train_df.reset_index(drop=True)\n",
        "cleaned_train_df = pd.concat([cleaned_train_df, ohe_df], axis=1)\n",
        "\n",
        "enc.fit(cleaned_train_df['month'].to_numpy().reshape(-1, 1))\n",
        "month_onehot = enc.transform(cleaned_train_df['month'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Make the 2d array a pandas series\n",
        "ohe_df = pd.DataFrame(month_onehot, columns=enc.get_feature_names())\n",
        "\n",
        "cleaned_train_df = cleaned_train_df.drop(['month'], axis=1)\n",
        "cleaned_train_df = cleaned_train_df.reset_index(drop=True)\n",
        "cleaned_train_df = pd.concat([cleaned_train_df, ohe_df], axis=1)\n",
        "\n",
        "enc.fit(cleaned_train_df['nature'].to_numpy().reshape(-1, 1))\n",
        "nature_onehot = enc.transform(cleaned_train_df['nature'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Make the 2d array a pandas series\n",
        "ohe_df = pd.DataFrame(nature_onehot, columns=enc.get_feature_names())\n",
        "\n",
        "cleaned_train_df = cleaned_train_df.drop(['nature'], axis=1)\n",
        "cleaned_train_df = cleaned_train_df.reset_index(drop=True)\n",
        "cleaned_train_df = pd.concat([cleaned_train_df, ohe_df], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "enc.fit(cleaned_train_df['type'].to_numpy().reshape(-1, 1))\n",
        "type_onehot = enc.transform(cleaned_train_df['type'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Make the 2d array a pandas series\n",
        "ohe_df = pd.DataFrame(type_onehot, columns=enc.get_feature_names())\n",
        "\n",
        "cleaned_train_df = cleaned_train_df.drop(['type'], axis=1)\n",
        "cleaned_train_df = cleaned_train_df.reset_index(drop=True)\n",
        "cleaned_train_df = pd.concat([cleaned_train_df, ohe_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCrFDpminT0N"
      },
      "source": [
        "#Test DataFrame encoding\n",
        "test_df.fillna(\"Other\", inplace=True)\n",
        "\n",
        "test_df.drop(columns=['user','session','query', 'timestamp','cpvs'], inplace = True)\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "enc.fit(test_df['search'].to_numpy().reshape(-1, 1))\n",
        "search_onehot = enc.transform(test_df['search'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Make the 2d array a pandas series\n",
        "ohe_df = pd.DataFrame(search_onehot, columns=enc.get_feature_names())\n",
        "\n",
        "test_df = test_df.drop(['search'], axis=1)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "test_df = pd.concat([test_df, ohe_df], axis=1)\n",
        "\n",
        "enc.fit(test_df['source'].to_numpy().reshape(-1, 1))\n",
        "source_onehot = enc.transform(test_df['source'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Make the 2d array a pandas series\n",
        "ohe_df = pd.DataFrame(source_onehot, columns=enc.get_feature_names())\n",
        "\n",
        "test_df = test_df.drop(['source'], axis=1)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "test_df = pd.concat([test_df, ohe_df], axis=1)\n",
        "\n",
        "enc.fit(test_df['day'].to_numpy().reshape(-1, 1))\n",
        "day_onehot = enc.transform(test_df['day'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Make the 2d array a pandas series\n",
        "ohe_df = pd.DataFrame(day_onehot, columns=enc.get_feature_names())\n",
        "\n",
        "test_df = test_df.drop(['day'], axis=1)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "test_df = pd.concat([test_df, ohe_df], axis=1)\n",
        "\n",
        "enc.fit(test_df['month'].to_numpy().reshape(-1, 1))\n",
        "month_onehot = enc.transform(test_df['month'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Make the 2d array a pandas series\n",
        "ohe_df = pd.DataFrame(month_onehot, columns=enc.get_feature_names())\n",
        "\n",
        "test_df = test_df.drop(['month'], axis=1)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "test_df = pd.concat([test_df, ohe_df], axis=1)\n",
        "\n",
        "enc.fit(test_df['nature'].to_numpy().reshape(-1, 1))\n",
        "nature_onehot = enc.transform(test_df['nature'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Make the 2d array a pandas series\n",
        "ohe_df = pd.DataFrame(nature_onehot, columns=enc.get_feature_names())\n",
        "\n",
        "test_df = test_df.drop(['nature'], axis=1)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "test_df = pd.concat([test_df, ohe_df], axis=1)\n",
        "\n",
        "enc.fit(test_df['type'].to_numpy().reshape(-1, 1))\n",
        "type_onehot = enc.transform(test_df['type'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Make the 2d array a pandas series\n",
        "ohe_df = pd.DataFrame(type_onehot, columns=enc.get_feature_names())\n",
        "\n",
        "test_df = test_df.drop(['type'], axis=1)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "test_df = pd.concat([test_df, ohe_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbUeW1bjq9JD"
      },
      "source": [
        "# Use a utility from sklearn to split and shuffle our dataset.\n",
        "train_df, val_df = train_test_split(cleaned_train_df, test_size=0.2,random_state=SEED)\n",
        "\n",
        "# Form np arrays of labels and features.\n",
        "train_labels = np.array(train_df.pop('psrel'))\n",
        "val_labels = np.array(val_df.pop('psrel'))\n",
        "train_features = np.array(train_df)\n",
        "val_features = np.array(val_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jjsVAwwq_Vo"
      },
      "source": [
        "#Scale the training and validation data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCMjThIvJxxm"
      },
      "source": [
        "#Data augmentation/oversampling\n",
        "oversample = SMOTE()\n",
        "train_features_oversampled, train_labels_oversampled = oversample.fit_resample(train_features, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUcARGm-J8gj",
        "outputId": "8c0a13fe-97c6-4896-8d40-e0c766dbe7f0"
      },
      "source": [
        "neg, pos = np.bincount(train_labels_oversampled)\n",
        "total = neg + pos\n",
        "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, pos, 100 * pos / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Examples:\n",
            "    Total: 49666\n",
            "    Positive: 24833 (50.00% of total)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUMTCoV76iBS",
        "outputId": "d8bd86da-6374-441a-a8ef-a5785b92e08d"
      },
      "source": [
        "#Grid search for Gradient Boosting Classifier (Takes 3hrs to run)\n",
        "parameters = {\n",
        "    \"max_depth\": [3, 5, 10, 15, 20, 25, 30, 60, None],\n",
        "    \"n_estimators\": [100, 200, 300, 500],\n",
        "    \"learning_rate\":[0.1, 0.3, 0.5, 0.8],\n",
        "}\n",
        "grid_search = GridSearchCV(estimator=GradientBoostingClassifier(), param_grid=parameters, return_train_score=True, scoring='f1_macro')\n",
        "grid_search = grid_search.fit(train_features, train_labels)\n",
        "grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgWWjw8QyhjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06a4833-64d6-47ac-8fa5-963bddb67526"
      },
      "source": [
        "#GradientBoostingClassifier initilization and prediction\n",
        "gb_clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=5)\n",
        "#gb_clf.fit(train_features,train_labels)\n",
        "gb_clf.fit(train_features_oversampled, train_labels_oversampled)\n",
        "y_predicted_gbc = gb_clf.predict(test_df)\n",
        "y_predicted_gbc = y_predicted_gbc.reshape(-1,1)\n",
        "\n",
        "#scores = cross_validate(gb_clf, train_features, train_labels, cv=10,scoring=('f1_macro'), return_train_score=True)\n",
        "scores = cross_validate(gb_clf, train_features_oversampled, train_labels_oversampled, cv=10,scoring=('f1_macro'), return_train_score=True)\n",
        "print(\"Training Score: \" + str(np.average(scores['train_score'])))\n",
        "print(\"Test Score: \" + str(np.average(scores['test_score'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Score: 0.9459554324378765\n",
            "Test Score: 0.9396229597614969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR2JUhX3gTuu"
      },
      "source": [
        "#Reshape train and validation data for the RNN\n",
        "train_features_rnn = train_features.reshape(train_features.shape[0], 1, train_features.shape[1])\n",
        "train_features_oversampled_rnn = train_features_oversampled.reshape(train_features_oversampled.shape[0], 1, train_features_oversampled.shape[1])\n",
        "val_features_rnn = val_features.reshape(val_features.shape[0], 1,  val_features.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MydvP4Ybd83F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ddf4ff0-a23c-46d8-9fd8-893231838319"
      },
      "source": [
        "# Given this function, we pass it through as a parameter to a Keras Classification Wrapper\n",
        "keras_class = keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_RNN_model)\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(monitor = 'loss', patience=3, restore_best_weights=True)\n",
        "keras_class_fit_oversampled = keras_class.fit(train_features_oversampled_rnn, train_labels_oversampled, callbacks = [early_stopping_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_32 (LSTM)               (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_33 (LSTM)               (None, 1, 30)             27720     \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 1, 30)             0         \n",
            "_________________________________________________________________\n",
            "lstm_34 (LSTM)               (None, 1, 30)             7320      \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 1, 30)             0         \n",
            "_________________________________________________________________\n",
            "lstm_35 (LSTM)               (None, 1, 30)             7320      \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 1, 30)             0         \n",
            "_________________________________________________________________\n",
            "lstm_36 (LSTM)               (None, 1, 30)             7320      \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 1, 30)             0         \n",
            "_________________________________________________________________\n",
            "lstm_37 (LSTM)               (None, 1, 30)             7320      \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 1, 30)             0         \n",
            "_________________________________________________________________\n",
            "lstm_38 (LSTM)               (None, 1, 30)             7320      \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 1, 30)             0         \n",
            "_________________________________________________________________\n",
            "lstm_39 (LSTM)               (None, 30)                7320      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 267,671\n",
            "Trainable params: 267,671\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1553/1553 [==============================] - 34s 13ms/step - loss: 0.5816 - tp: 30682.7606 - fp: 5175.5766 - tn: 8595.5084 - fn: 3530.0952 - accuracy: 0.8282 - precision: 0.8620 - recall: 0.9038 - auc: 0.8522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuV6h_sj484p",
        "outputId": "e36f1bb6-558a-480c-8ba5-f82e146ea376"
      },
      "source": [
        "# Parameter space what we want explore\n",
        "# Note that it exactly matches up to our build_model function parameters.\n",
        "\n",
        "param_distribs = {\n",
        "    \"n_neurons\": np.arange(25,35),\n",
        "    \"learning_rate\": [0.01,0.02]\n",
        "}\n",
        "\n",
        "# How many possible combinations do we have ?? 30 * 3 = 90?\n",
        "\n",
        "# Set up the search - trying n_iter possibilities for cv folds OVERSAMPLED\n",
        "#rnd_search_cv_oversampled = RandomizedSearchCV(keras_class, param_distribs, n_iter=10, cv=2)\n",
        "#rnd_search_cv_oversampled.fit(train_features_oversampled, train_labels_oversampled, epochs=50, validation_data=(val_features, val_labels), callbacks=[early_stopping_cb])\n",
        "\n",
        "#Non-oversampled rnd_search_cv\n",
        "rnd_search_cv = RandomizedSearchCV(keras_class, param_distribs, n_iter=10, cv=2)\n",
        "rnd_search_cv.fit(train_features_oversampled_rnn, train_labels_oversampled, epochs=50, callbacks=[early_stopping_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_40 (LSTM)               (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_41 (LSTM)               (None, 1, 32)             29824     \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_42 (LSTM)               (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_43 (LSTM)               (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_44 (LSTM)               (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_45 (LSTM)               (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_46 (LSTM)               (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_47 (LSTM)               (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 275,777\n",
            "Trainable params: 275,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 25s 13ms/step - loss: 0.2364 - tp: 52003.8907 - fp: 9189.9075 - tn: 17757.6967 - fn: 6282.3843 - accuracy: 0.8176 - precision: 0.8485 - recall: 0.8907 - auc: 0.8765\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 10s 14ms/step - loss: 0.2148 - tp: 11728.9049 - fp: 734.9743 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9409 - precision: 0.9409 - recall: 1.0000 - auc: 0.6037\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 10s 13ms/step - loss: 0.2228 - tp: 11697.0103 - fp: 766.8689 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9365 - precision: 0.9365 - recall: 1.0000 - auc: 0.6536\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 10s 13ms/step - loss: 0.2035 - tp: 11748.6337 - fp: 715.2455 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9433 - precision: 0.9433 - recall: 1.0000 - auc: 0.6334\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 10s 13ms/step - loss: 0.2092 - tp: 11712.1234 - fp: 732.6298 - tn: 6.3201 - fn: 12.8059 - accuracy: 0.9393 - precision: 0.9400 - recall: 0.9992 - auc: 0.6473\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2027 - tp: 11747.3869 - fp: 716.4923 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9427 - precision: 0.9427 - recall: 1.0000 - auc: 0.6652\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2064 - tp: 11735.9126 - fp: 727.9666 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9415 - precision: 0.9415 - recall: 1.0000 - auc: 0.6758\n",
            "777/777 [==============================] - 7s 4ms/step - loss: 1.9981 - tp: 1472.0000 - fp: 23361.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0593 - precision: 0.0593 - recall: 1.0000 - auc: 0.6709\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_48 (LSTM)               (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_49 (LSTM)               (None, 1, 32)             29824     \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_50 (LSTM)               (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_51 (LSTM)               (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_52 (LSTM)               (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_53 (LSTM)               (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_54 (LSTM)               (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_55 (LSTM)               (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 275,777\n",
            "Trainable params: 275,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 25s 13ms/step - loss: 0.2476 - tp: 1473.0000 - fp: 23374.0000 - tn: 11701.9769 - fn: 747.9023 - accuracy: 0.3298 - precision: 0.0593 - recall: 0.6889 - auc: 0.5854\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2273 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11722.4524 - fn: 741.4267 - accuracy: 0.9403 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5048\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2224 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11729.0077 - fn: 734.8715 - accuracy: 0.9416 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5451\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2316 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11710.3907 - fn: 753.4884 - accuracy: 0.9388 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5101\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2263 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11709.2622 - fn: 754.6170 - accuracy: 0.9393 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5742\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2241 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11728.8368 - fn: 735.0424 - accuracy: 0.9416 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4786\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2216 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11743.2365 - fn: 720.6427 - accuracy: 0.9423 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4958\n",
            "Epoch 8/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11712.5064 - fn: 751.3728 - accuracy: 0.9388 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5085\n",
            "777/777 [==============================] - 7s 4ms/step - loss: 2.9609 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1472.0000 - fn: 23361.0000 - accuracy: 0.0593 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_56 (LSTM)               (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_57 (LSTM)               (None, 1, 33)             30888     \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_58 (LSTM)               (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_59 (LSTM)               (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_60 (LSTM)               (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_61 (LSTM)               (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_62 (LSTM)               (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_63 (LSTM)               (None, 33)                8844      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 34        \n",
            "=================================================================\n",
            "Total params: 279,986\n",
            "Trainable params: 279,986\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 26s 14ms/step - loss: 0.2413 - tp: 11678.1452 - fp: 720.4871 - tn: 1494.1170 - fn: 23404.1298 - accuracy: 0.3298 - precision: 0.9411 - recall: 0.3064 - auc: 0.5142\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1905 - tp: 11625.0039 - fp: 589.7532 - tn: 145.2211 - fn: 103.9010 - accuracy: 0.9448 - precision: 0.9519 - recall: 0.9915 - auc: 0.7320\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1906 - tp: 11646.2082 - fp: 701.7853 - tn: 65.0835 - fn: 50.8021 - accuracy: 0.9374 - precision: 0.9403 - recall: 0.9965 - auc: 0.7904\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1615 - tp: 11658.1530 - fp: 507.8008 - tn: 207.4447 - fn: 90.4807 - accuracy: 0.9524 - precision: 0.9584 - recall: 0.9927 - auc: 0.8203\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1573 - tp: 11631.6645 - fp: 494.8355 - tn: 244.1144 - fn: 93.2648 - accuracy: 0.9522 - precision: 0.9584 - recall: 0.9922 - auc: 0.8566\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1370 - tp: 11673.2326 - fp: 438.8548 - tn: 277.6375 - fn: 74.1542 - accuracy: 0.9593 - precision: 0.9645 - recall: 0.9934 - auc: 0.8739\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1348 - tp: 11666.2596 - fp: 414.6041 - tn: 313.3625 - fn: 69.6530 - accuracy: 0.9611 - precision: 0.9656 - recall: 0.9941 - auc: 0.8720\n",
            "Epoch 8/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1311 - tp: 11689.2828 - fp: 418.8830 - tn: 297.6992 - fn: 58.0141 - accuracy: 0.9610 - precision: 0.9652 - recall: 0.9946 - auc: 0.8852\n",
            "Epoch 9/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1265 - tp: 11639.3535 - fp: 397.4422 - tn: 360.2841 - fn: 66.7995 - accuracy: 0.9626 - precision: 0.9668 - recall: 0.9944 - auc: 0.8920\n",
            "Epoch 10/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1189 - tp: 11652.3676 - fp: 387.6375 - tn: 349.4216 - fn: 74.4524 - accuracy: 0.9627 - precision: 0.9684 - recall: 0.9927 - auc: 0.9029\n",
            "Epoch 11/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1231 - tp: 11638.5668 - fp: 361.6362 - tn: 391.6427 - fn: 72.0334 - accuracy: 0.9658 - precision: 0.9703 - recall: 0.9940 - auc: 0.8989\n",
            "Epoch 12/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1196 - tp: 11654.4049 - fp: 332.4126 - tn: 400.4165 - fn: 76.6452 - accuracy: 0.9677 - precision: 0.9724 - recall: 0.9940 - auc: 0.8924\n",
            "Epoch 13/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1153 - tp: 11639.3638 - fp: 342.4113 - tn: 406.6170 - fn: 75.4871 - accuracy: 0.9670 - precision: 0.9716 - recall: 0.9940 - auc: 0.9113\n",
            "Epoch 14/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1193 - tp: 11646.2481 - fp: 317.3946 - tn: 402.8985 - fn: 97.3380 - accuracy: 0.9667 - precision: 0.9727 - recall: 0.9925 - auc: 0.8985\n",
            "Epoch 15/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1126 - tp: 11636.7853 - fp: 300.8509 - tn: 429.4936 - fn: 96.7494 - accuracy: 0.9688 - precision: 0.9758 - recall: 0.9915 - auc: 0.9074\n",
            "Epoch 16/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1035 - tp: 11688.1697 - fp: 330.6555 - tn: 419.4087 - fn: 25.6452 - accuracy: 0.9730 - precision: 0.9740 - recall: 0.9980 - auc: 0.8894\n",
            "Epoch 17/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1057 - tp: 11676.7802 - fp: 304.2841 - tn: 430.1247 - fn: 52.6902 - accuracy: 0.9719 - precision: 0.9751 - recall: 0.9956 - auc: 0.9031\n",
            "Epoch 18/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.0970 - tp: 11664.6183 - fp: 272.7956 - tn: 448.4190 - fn: 78.0463 - accuracy: 0.9727 - precision: 0.9783 - recall: 0.9931 - auc: 0.9193\n",
            "Epoch 19/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1056 - tp: 11629.0283 - fp: 293.2121 - tn: 441.1388 - fn: 100.5000 - accuracy: 0.9703 - precision: 0.9761 - recall: 0.9928 - auc: 0.9231\n",
            "Epoch 20/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1118 - tp: 11616.1208 - fp: 306.0463 - tn: 432.0386 - fn: 109.6735 - accuracy: 0.9661 - precision: 0.9752 - recall: 0.9891 - auc: 0.9262\n",
            "Epoch 21/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.0989 - tp: 11660.2815 - fp: 312.7558 - tn: 421.5797 - fn: 69.2622 - accuracy: 0.9705 - precision: 0.9750 - recall: 0.9942 - auc: 0.9328\n",
            "777/777 [==============================] - 7s 4ms/step - loss: 1.6305 - tp: 1460.0000 - fp: 13290.0000 - tn: 10071.0000 - fn: 12.0000 - accuracy: 0.4643 - precision: 0.0990 - recall: 0.9918 - auc: 0.8641\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_64 (LSTM)               (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_65 (LSTM)               (None, 1, 33)             30888     \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_66 (LSTM)               (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_67 (LSTM)               (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_68 (LSTM)               (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_69 (LSTM)               (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_70 (LSTM)               (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_53 (Dropout)         (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_71 (LSTM)               (None, 33)                8844      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 34        \n",
            "=================================================================\n",
            "Total params: 279,986\n",
            "Trainable params: 279,986\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 26s 14ms/step - loss: 0.2441 - tp: 1492.7185 - fp: 13337.1825 - tn: 21738.7943 - fn: 728.1838 - accuracy: 0.6102 - precision: 0.1006 - recall: 0.6955 - auc: 0.7312\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1976 - tp: 103.3290 - fp: 44.5604 - tn: 11677.8920 - fn: 638.0977 - accuracy: 0.9446 - precision: 0.6720 - recall: 0.1283 - auc: 0.7209\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1846 - tp: 121.7147 - fp: 44.7545 - tn: 11684.2532 - fn: 613.1568 - accuracy: 0.9480 - precision: 0.7220 - recall: 0.1828 - auc: 0.7391\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1954 - tp: 83.6851 - fp: 17.5874 - tn: 11692.8033 - fn: 669.8033 - accuracy: 0.9448 - precision: 0.8464 - recall: 0.1205 - auc: 0.7333\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1896 - tp: 141.2031 - fp: 93.1542 - tn: 11616.1080 - fn: 613.4139 - accuracy: 0.9428 - precision: 0.5855 - recall: 0.1830 - auc: 0.7230\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1849 - tp: 104.8329 - fp: 24.3753 - tn: 11704.4614 - fn: 630.2095 - accuracy: 0.9478 - precision: 0.7887 - recall: 0.1461 - auc: 0.7267\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1829 - tp: 112.5540 - fp: 52.5501 - tn: 11690.6864 - fn: 608.0887 - accuracy: 0.9469 - precision: 0.6902 - recall: 0.1426 - auc: 0.7233\n",
            "Epoch 8/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1888 - tp: 131.1915 - fp: 49.7558 - tn: 11662.7506 - fn: 620.1812 - accuracy: 0.9456 - precision: 0.7277 - recall: 0.1771 - auc: 0.7230\n",
            "Epoch 9/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1883 - tp: 94.3933 - fp: 39.2159 - tn: 11693.3265 - fn: 636.9434 - accuracy: 0.9462 - precision: 0.7584 - recall: 0.1131 - auc: 0.7060\n",
            "Epoch 10/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1832 - tp: 136.1465 - fp: 47.8239 - tn: 11676.7558 - fn: 603.1530 - accuracy: 0.9473 - precision: 0.7188 - recall: 0.1899 - auc: 0.7233\n",
            "Epoch 11/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1811 - tp: 150.8483 - fp: 39.8380 - tn: 11683.8985 - fn: 589.2943 - accuracy: 0.9494 - precision: 0.7870 - recall: 0.2056 - auc: 0.7453\n",
            "Epoch 12/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1835 - tp: 161.9229 - fp: 53.4846 - tn: 11655.4319 - fn: 593.0398 - accuracy: 0.9472 - precision: 0.7676 - recall: 0.2316 - auc: 0.7533\n",
            "Epoch 13/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1782 - tp: 150.3920 - fp: 79.2545 - tn: 11636.2044 - fn: 598.0283 - accuracy: 0.9471 - precision: 0.6664 - recall: 0.2106 - auc: 0.7543\n",
            "Epoch 14/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1827 - tp: 151.2622 - fp: 55.1093 - tn: 11674.9833 - fn: 582.5244 - accuracy: 0.9484 - precision: 0.7255 - recall: 0.2028 - auc: 0.7417\n",
            "777/777 [==============================] - 7s 4ms/step - loss: 2.0274 - tp: 4794.0000 - fp: 4.0000 - tn: 1468.0000 - fn: 18567.0000 - accuracy: 0.2522 - precision: 0.9992 - recall: 0.2052 - auc: 0.7865\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_72 (LSTM)               (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_73 (LSTM)               (None, 1, 34)             31960     \n",
            "_________________________________________________________________\n",
            "dropout_54 (Dropout)         (None, 1, 34)             0         \n",
            "_________________________________________________________________\n",
            "lstm_74 (LSTM)               (None, 1, 34)             9384      \n",
            "_________________________________________________________________\n",
            "dropout_55 (Dropout)         (None, 1, 34)             0         \n",
            "_________________________________________________________________\n",
            "lstm_75 (LSTM)               (None, 1, 34)             9384      \n",
            "_________________________________________________________________\n",
            "dropout_56 (Dropout)         (None, 1, 34)             0         \n",
            "_________________________________________________________________\n",
            "lstm_76 (LSTM)               (None, 1, 34)             9384      \n",
            "_________________________________________________________________\n",
            "dropout_57 (Dropout)         (None, 1, 34)             0         \n",
            "_________________________________________________________________\n",
            "lstm_77 (LSTM)               (None, 1, 34)             9384      \n",
            "_________________________________________________________________\n",
            "dropout_58 (Dropout)         (None, 1, 34)             0         \n",
            "_________________________________________________________________\n",
            "lstm_78 (LSTM)               (None, 1, 34)             9384      \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         (None, 1, 34)             0         \n",
            "_________________________________________________________________\n",
            "lstm_79 (LSTM)               (None, 34)                9384      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 35        \n",
            "=================================================================\n",
            "Total params: 284,299\n",
            "Trainable params: 284,299\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 26s 14ms/step - loss: 0.2399 - tp: 16498.7442 - fp: 744.9177 - tn: 1469.6864 - fn: 18583.5308 - accuracy: 0.4635 - precision: 0.9610 - recall: 0.4492 - auc: 0.6556\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2167 - tp: 11728.9049 - fp: 734.9743 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9409 - precision: 0.9409 - recall: 1.0000 - auc: 0.5937\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2221 - tp: 11697.0103 - fp: 766.8689 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9365 - precision: 0.9365 - recall: 1.0000 - auc: 0.6531\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2044 - tp: 11743.6208 - fp: 712.6272 - tn: 2.6183 - fn: 5.0129 - accuracy: 0.9431 - precision: 0.9435 - recall: 0.9995 - auc: 0.6308\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2126 - tp: 11724.9293 - fp: 738.9499 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9397 - precision: 0.9397 - recall: 1.0000 - auc: 0.6082\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2088 - tp: 11747.3869 - fp: 716.4923 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9427 - precision: 0.9427 - recall: 1.0000 - auc: 0.6503\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2038 - tp: 11722.9409 - fp: 723.4550 - tn: 4.5116 - fn: 12.9717 - accuracy: 0.9409 - precision: 0.9417 - recall: 0.9990 - auc: 0.6609\n",
            "Epoch 8/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2055 - tp: 11743.7237 - fp: 712.9512 - tn: 3.6311 - fn: 3.5733 - accuracy: 0.9429 - precision: 0.9431 - recall: 0.9998 - auc: 0.6235\n",
            "Epoch 9/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2181 - tp: 11706.1388 - fp: 757.7262 - tn: 0.0000e+00 - fn: 0.0141 - accuracy: 0.9392 - precision: 0.9392 - recall: 1.0000 - auc: 0.6195\n",
            "Epoch 10/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2087 - tp: 11726.8201 - fp: 737.0591 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9406 - precision: 0.9406 - recall: 1.0000 - auc: 0.6781\n",
            "Epoch 11/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2074 - tp: 11706.3162 - fp: 750.8753 - tn: 2.4036 - fn: 4.2841 - accuracy: 0.9389 - precision: 0.9393 - recall: 0.9996 - auc: 0.7006\n",
            "Epoch 12/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2091 - tp: 11727.6761 - fp: 728.4460 - tn: 4.3830 - fn: 3.3740 - accuracy: 0.9420 - precision: 0.9423 - recall: 0.9997 - auc: 0.6544\n",
            "Epoch 13/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2133 - tp: 11713.7841 - fp: 746.8213 - tn: 2.2069 - fn: 1.0668 - accuracy: 0.9401 - precision: 0.9401 - recall: 0.9999 - auc: 0.6598\n",
            "777/777 [==============================] - 7s 4ms/step - loss: 2.5319 - tp: 1472.0000 - fp: 23361.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0593 - precision: 0.0593 - recall: 1.0000 - auc: 0.7026\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_80 (LSTM)               (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_81 (LSTM)               (None, 1, 34)             31960     \n",
            "_________________________________________________________________\n",
            "dropout_60 (Dropout)         (None, 1, 34)             0         \n",
            "_________________________________________________________________\n",
            "lstm_82 (LSTM)               (None, 1, 34)             9384      \n",
            "_________________________________________________________________\n",
            "dropout_61 (Dropout)         (None, 1, 34)             0         \n",
            "_________________________________________________________________\n",
            "lstm_83 (LSTM)               (None, 1, 34)             9384      \n",
            "_________________________________________________________________\n",
            "dropout_62 (Dropout)         (None, 1, 34)             0         \n",
            "_________________________________________________________________\n",
            "lstm_84 (LSTM)               (None, 1, 34)             9384      \n",
            "_________________________________________________________________\n",
            "dropout_63 (Dropout)         (None, 1, 34)             0         \n",
            "_________________________________________________________________\n",
            "lstm_85 (LSTM)               (None, 1, 34)             9384      \n",
            "_________________________________________________________________\n",
            "dropout_64 (Dropout)         (None, 1, 34)             0         \n",
            "_________________________________________________________________\n",
            "lstm_86 (LSTM)               (None, 1, 34)             9384      \n",
            "_________________________________________________________________\n",
            "dropout_65 (Dropout)         (None, 1, 34)             0         \n",
            "_________________________________________________________________\n",
            "lstm_87 (LSTM)               (None, 34)                9384      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 35        \n",
            "=================================================================\n",
            "Total params: 284,299\n",
            "Trainable params: 284,299\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 26s 14ms/step - loss: 0.2449 - tp: 1472.0000 - fp: 23375.0000 - tn: 11700.9769 - fn: 748.9023 - accuracy: 0.3298 - precision: 0.0592 - recall: 0.6885 - auc: 0.6025\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2243 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11722.4524 - fn: 741.4267 - accuracy: 0.9403 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5373\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2243 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11729.0077 - fn: 734.8715 - accuracy: 0.9416 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4862\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2319 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11710.3907 - fn: 753.4884 - accuracy: 0.9388 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4998\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.2300 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11709.2622 - fn: 754.6170 - accuracy: 0.9393 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4923\n",
            "777/777 [==============================] - 8s 4ms/step - loss: 2.6221 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1472.0000 - fn: 23361.0000 - accuracy: 0.0593 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_88 (LSTM)               (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_89 (LSTM)               (None, 1, 29)             26680     \n",
            "_________________________________________________________________\n",
            "dropout_66 (Dropout)         (None, 1, 29)             0         \n",
            "_________________________________________________________________\n",
            "lstm_90 (LSTM)               (None, 1, 29)             6844      \n",
            "_________________________________________________________________\n",
            "dropout_67 (Dropout)         (None, 1, 29)             0         \n",
            "_________________________________________________________________\n",
            "lstm_91 (LSTM)               (None, 1, 29)             6844      \n",
            "_________________________________________________________________\n",
            "dropout_68 (Dropout)         (None, 1, 29)             0         \n",
            "_________________________________________________________________\n",
            "lstm_92 (LSTM)               (None, 1, 29)             6844      \n",
            "_________________________________________________________________\n",
            "dropout_69 (Dropout)         (None, 1, 29)             0         \n",
            "_________________________________________________________________\n",
            "lstm_93 (LSTM)               (None, 1, 29)             6844      \n",
            "_________________________________________________________________\n",
            "dropout_70 (Dropout)         (None, 1, 29)             0         \n",
            "_________________________________________________________________\n",
            "lstm_94 (LSTM)               (None, 1, 29)             6844      \n",
            "_________________________________________________________________\n",
            "dropout_71 (Dropout)         (None, 1, 29)             0         \n",
            "_________________________________________________________________\n",
            "lstm_95 (LSTM)               (None, 29)                6844      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 30        \n",
            "=================================================================\n",
            "Total params: 263,774\n",
            "Trainable params: 263,774\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 26s 14ms/step - loss: 0.2490 - tp: 11705.2751 - fp: 742.6041 - tn: 1472.0000 - fn: 23377.0000 - accuracy: 0.3299 - precision: 0.9400 - recall: 0.3071 - auc: 0.5112\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.2097 - tp: 11728.9049 - fp: 734.9743 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9409 - precision: 0.9409 - recall: 1.0000 - auc: 0.6446\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.2165 - tp: 11697.0103 - fp: 766.8689 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9365 - precision: 0.9365 - recall: 1.0000 - auc: 0.6516\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1962 - tp: 11748.6337 - fp: 715.2455 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9433 - precision: 0.9433 - recall: 1.0000 - auc: 0.6452\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.2058 - tp: 11724.3766 - fp: 738.6504 - tn: 0.2995 - fn: 0.5527 - accuracy: 0.9397 - precision: 0.9397 - recall: 1.0000 - auc: 0.6372\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1872 - tp: 11716.4602 - fp: 682.8882 - tn: 33.6041 - fn: 30.9267 - accuracy: 0.9428 - precision: 0.9443 - recall: 0.9983 - auc: 0.6768\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1861 - tp: 11618.5887 - fp: 549.0578 - tn: 178.9087 - fn: 117.3239 - accuracy: 0.9461 - precision: 0.9550 - recall: 0.9894 - auc: 0.6919\n",
            "Epoch 8/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1872 - tp: 11639.0566 - fp: 552.8625 - tn: 163.7198 - fn: 108.2404 - accuracy: 0.9463 - precision: 0.9542 - recall: 0.9906 - auc: 0.6601\n",
            "Epoch 9/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1896 - tp: 11560.6658 - fp: 569.6054 - tn: 188.1208 - fn: 145.4871 - accuracy: 0.9433 - precision: 0.9537 - recall: 0.9876 - auc: 0.6888\n",
            "Epoch 10/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1788 - tp: 11663.4306 - fp: 580.4666 - tn: 156.5925 - fn: 63.3895 - accuracy: 0.9480 - precision: 0.9529 - recall: 0.9938 - auc: 0.7251\n",
            "Epoch 11/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1835 - tp: 11578.9627 - fp: 550.6221 - tn: 202.6568 - fn: 131.6375 - accuracy: 0.9443 - precision: 0.9546 - recall: 0.9877 - auc: 0.7432\n",
            "Epoch 12/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1683 - tp: 11664.1452 - fp: 524.4332 - tn: 208.3959 - fn: 66.9049 - accuracy: 0.9533 - precision: 0.9574 - recall: 0.9946 - auc: 0.7506\n",
            "Epoch 13/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1739 - tp: 11590.6889 - fp: 503.9897 - tn: 245.0386 - fn: 124.1620 - accuracy: 0.9483 - precision: 0.9583 - recall: 0.9880 - auc: 0.7756\n",
            "Epoch 14/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1610 - tp: 11672.5103 - fp: 469.4216 - tn: 250.8715 - fn: 71.0758 - accuracy: 0.9556 - precision: 0.9599 - recall: 0.9943 - auc: 0.7745\n",
            "Epoch 15/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1486 - tp: 11673.6941 - fp: 454.3946 - tn: 275.9499 - fn: 59.8406 - accuracy: 0.9610 - precision: 0.9645 - recall: 0.9952 - auc: 0.7672\n",
            "Epoch 16/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1519 - tp: 11669.0707 - fp: 471.5733 - tn: 278.4910 - fn: 44.7442 - accuracy: 0.9594 - precision: 0.9620 - recall: 0.9962 - auc: 0.7819\n",
            "Epoch 17/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1470 - tp: 11680.8676 - fp: 436.6015 - tn: 297.8072 - fn: 48.6028 - accuracy: 0.9613 - precision: 0.9639 - recall: 0.9962 - auc: 0.7958\n",
            "Epoch 18/50\n",
            "777/777 [==============================] - 11s 14ms/step - loss: 0.1411 - tp: 11686.2609 - fp: 409.1234 - tn: 312.0913 - fn: 56.4036 - accuracy: 0.9637 - precision: 0.9668 - recall: 0.9957 - auc: 0.7967\n",
            "Epoch 19/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1461 - tp: 11674.5103 - fp: 428.8162 - tn: 305.5347 - fn: 55.0180 - accuracy: 0.9615 - precision: 0.9651 - recall: 0.9950 - auc: 0.7903\n",
            "Epoch 20/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1380 - tp: 11675.7352 - fp: 400.0386 - tn: 338.0463 - fn: 50.0591 - accuracy: 0.9646 - precision: 0.9677 - recall: 0.9956 - auc: 0.8179\n",
            "Epoch 21/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1377 - tp: 11650.0013 - fp: 399.4473 - tn: 334.8882 - fn: 79.5424 - accuracy: 0.9627 - precision: 0.9679 - recall: 0.9934 - auc: 0.8504\n",
            "Epoch 22/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1382 - tp: 11649.9049 - fp: 395.5219 - tn: 329.9396 - fn: 88.5129 - accuracy: 0.9633 - precision: 0.9684 - recall: 0.9935 - auc: 0.8299\n",
            "Epoch 23/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1495 - tp: 11620.5398 - fp: 442.9087 - tn: 309.0630 - fn: 91.3676 - accuracy: 0.9563 - precision: 0.9619 - recall: 0.9928 - auc: 0.8369\n",
            "777/777 [==============================] - 8s 5ms/step - loss: 1.6917 - tp: 1461.0000 - fp: 14913.0000 - tn: 8448.0000 - fn: 11.0000 - accuracy: 0.3990 - precision: 0.0892 - recall: 0.9925 - auc: 0.8280\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_96 (LSTM)               (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_97 (LSTM)               (None, 1, 29)             26680     \n",
            "_________________________________________________________________\n",
            "dropout_72 (Dropout)         (None, 1, 29)             0         \n",
            "_________________________________________________________________\n",
            "lstm_98 (LSTM)               (None, 1, 29)             6844      \n",
            "_________________________________________________________________\n",
            "dropout_73 (Dropout)         (None, 1, 29)             0         \n",
            "_________________________________________________________________\n",
            "lstm_99 (LSTM)               (None, 1, 29)             6844      \n",
            "_________________________________________________________________\n",
            "dropout_74 (Dropout)         (None, 1, 29)             0         \n",
            "_________________________________________________________________\n",
            "lstm_100 (LSTM)              (None, 1, 29)             6844      \n",
            "_________________________________________________________________\n",
            "dropout_75 (Dropout)         (None, 1, 29)             0         \n",
            "_________________________________________________________________\n",
            "lstm_101 (LSTM)              (None, 1, 29)             6844      \n",
            "_________________________________________________________________\n",
            "dropout_76 (Dropout)         (None, 1, 29)             0         \n",
            "_________________________________________________________________\n",
            "lstm_102 (LSTM)              (None, 1, 29)             6844      \n",
            "_________________________________________________________________\n",
            "dropout_77 (Dropout)         (None, 1, 29)             0         \n",
            "_________________________________________________________________\n",
            "lstm_103 (LSTM)              (None, 29)                6844      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 30        \n",
            "=================================================================\n",
            "Total params: 263,774\n",
            "Trainable params: 263,774\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 27s 15ms/step - loss: 0.2526 - tp: 1468.4846 - fp: 14939.9087 - tn: 20136.0681 - fn: 752.4177 - accuracy: 0.5649 - precision: 0.0895 - recall: 0.6861 - auc: 0.6941\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.2041 - tp: 81.0540 - fp: 62.2455 - tn: 11660.2069 - fn: 660.3728 - accuracy: 0.9412 - precision: 0.5442 - recall: 0.1093 - auc: 0.6912\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1900 - tp: 114.2763 - fp: 39.1902 - tn: 11689.8175 - fn: 620.5951 - accuracy: 0.9475 - precision: 0.7463 - recall: 0.1546 - auc: 0.7154\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1936 - tp: 112.7661 - fp: 38.5000 - tn: 11671.8907 - fn: 640.7224 - accuracy: 0.9448 - precision: 0.7507 - recall: 0.1479 - auc: 0.7344\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1865 - tp: 132.9383 - fp: 34.4370 - tn: 11674.8252 - fn: 621.6787 - accuracy: 0.9474 - precision: 0.8158 - recall: 0.1726 - auc: 0.7528\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1801 - tp: 111.1221 - fp: 31.9910 - tn: 11696.8458 - fn: 623.9203 - accuracy: 0.9480 - precision: 0.7688 - recall: 0.1546 - auc: 0.7687\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1804 - tp: 119.7262 - fp: 34.6748 - tn: 11708.5617 - fn: 600.9165 - accuracy: 0.9489 - precision: 0.7616 - recall: 0.1642 - auc: 0.7303\n",
            "Epoch 8/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1875 - tp: 105.3252 - fp: 37.1774 - tn: 11675.3290 - fn: 646.0476 - accuracy: 0.9445 - precision: 0.7381 - recall: 0.1423 - auc: 0.7587\n",
            "Epoch 9/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1771 - tp: 151.2095 - fp: 60.3959 - tn: 11672.1465 - fn: 580.1272 - accuracy: 0.9494 - precision: 0.7232 - recall: 0.2090 - auc: 0.7470\n",
            "Epoch 10/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1802 - tp: 125.1311 - fp: 40.1722 - tn: 11684.4075 - fn: 614.1684 - accuracy: 0.9481 - precision: 0.7660 - recall: 0.1832 - auc: 0.7533\n",
            "Epoch 11/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1813 - tp: 112.4486 - fp: 47.9383 - tn: 11675.7982 - fn: 627.6941 - accuracy: 0.9465 - precision: 0.7196 - recall: 0.1631 - auc: 0.7470\n",
            "Epoch 12/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1873 - tp: 157.8021 - fp: 59.7892 - tn: 11649.1272 - fn: 597.1607 - accuracy: 0.9458 - precision: 0.7488 - recall: 0.2159 - auc: 0.7350\n",
            "Epoch 13/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1773 - tp: 117.2159 - fp: 37.9036 - tn: 11677.5553 - fn: 631.2044 - accuracy: 0.9478 - precision: 0.8023 - recall: 0.1567 - auc: 0.7567\n",
            "Epoch 14/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1789 - tp: 139.6799 - fp: 58.3393 - tn: 11671.7532 - fn: 594.1067 - accuracy: 0.9477 - precision: 0.7040 - recall: 0.1988 - auc: 0.7614\n",
            "Epoch 15/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1757 - tp: 156.7301 - fp: 53.8072 - tn: 11671.7969 - fn: 581.5450 - accuracy: 0.9487 - precision: 0.7685 - recall: 0.2081 - auc: 0.7770\n",
            "Epoch 16/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1759 - tp: 173.9062 - fp: 91.5463 - tn: 11645.3316 - fn: 553.0951 - accuracy: 0.9488 - precision: 0.6492 - recall: 0.2324 - auc: 0.7356\n",
            "Epoch 17/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1781 - tp: 165.9653 - fp: 69.8869 - tn: 11651.7391 - fn: 576.2879 - accuracy: 0.9479 - precision: 0.7049 - recall: 0.2221 - auc: 0.7556\n",
            "Epoch 18/50\n",
            "777/777 [==============================] - 11s 15ms/step - loss: 0.1759 - tp: 182.2378 - fp: 67.8419 - tn: 11656.2828 - fn: 557.5167 - accuracy: 0.9487 - precision: 0.7256 - recall: 0.2426 - auc: 0.7566\n",
            "Epoch 19/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1794 - tp: 174.2301 - fp: 84.7995 - tn: 11639.4524 - fn: 565.3972 - accuracy: 0.9477 - precision: 0.6591 - recall: 0.2258 - auc: 0.7195\n",
            "Epoch 20/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1814 - tp: 138.7185 - fp: 71.8419 - tn: 11668.3123 - fn: 585.0064 - accuracy: 0.9461 - precision: 0.6544 - recall: 0.1874 - auc: 0.7294\n",
            "777/777 [==============================] - 7s 5ms/step - loss: 2.0289 - tp: 6224.0000 - fp: 13.0000 - tn: 1459.0000 - fn: 17137.0000 - accuracy: 0.3094 - precision: 0.9979 - recall: 0.2664 - auc: 0.7816\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_104 (LSTM)              (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_105 (LSTM)              (None, 1, 32)             29824     \n",
            "_________________________________________________________________\n",
            "dropout_78 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_106 (LSTM)              (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_79 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_107 (LSTM)              (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_80 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_108 (LSTM)              (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_81 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_109 (LSTM)              (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_82 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_110 (LSTM)              (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_83 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_111 (LSTM)              (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 275,777\n",
            "Trainable params: 275,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 26s 15ms/step - loss: 0.2450 - tp: 17916.5026 - fp: 744.9010 - tn: 1469.7031 - fn: 17165.7725 - accuracy: 0.5030 - precision: 0.9639 - recall: 0.4912 - auc: 0.6654\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1910 - tp: 11703.3021 - fp: 697.3728 - tn: 37.6015 - fn: 25.6028 - accuracy: 0.9415 - precision: 0.9427 - recall: 0.9986 - auc: 0.7541\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.2002 - tp: 11629.2404 - fp: 707.1298 - tn: 59.7391 - fn: 67.7699 - accuracy: 0.9362 - precision: 0.9403 - recall: 0.9951 - auc: 0.7292\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1751 - tp: 11743.4589 - fp: 710.0360 - tn: 5.2095 - fn: 5.1748 - accuracy: 0.9433 - precision: 0.9435 - recall: 0.9998 - auc: 0.8058\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1718 - tp: 11548.6491 - fp: 550.1645 - tn: 188.7853 - fn: 176.2802 - accuracy: 0.9397 - precision: 0.9520 - recall: 0.9855 - auc: 0.8188\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1560 - tp: 11607.8470 - fp: 510.4743 - tn: 206.0180 - fn: 139.5398 - accuracy: 0.9479 - precision: 0.9587 - recall: 0.9873 - auc: 0.8477\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1478 - tp: 11638.8483 - fp: 472.4280 - tn: 255.5386 - fn: 97.0643 - accuracy: 0.9541 - precision: 0.9613 - recall: 0.9912 - auc: 0.8595\n",
            "Epoch 8/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1416 - tp: 11628.8792 - fp: 446.8085 - tn: 269.7738 - fn: 118.4177 - accuracy: 0.9541 - precision: 0.9631 - recall: 0.9892 - auc: 0.8711\n",
            "Epoch 9/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1430 - tp: 11603.3380 - fp: 441.4884 - tn: 316.2378 - fn: 102.8149 - accuracy: 0.9562 - precision: 0.9628 - recall: 0.9916 - auc: 0.8730\n",
            "Epoch 10/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1197 - tp: 11621.4974 - fp: 370.3740 - tn: 366.6851 - fn: 105.3226 - accuracy: 0.9626 - precision: 0.9702 - recall: 0.9906 - auc: 0.9099\n",
            "Epoch 11/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1266 - tp: 11651.5566 - fp: 384.3098 - tn: 368.9692 - fn: 59.0437 - accuracy: 0.9648 - precision: 0.9685 - recall: 0.9949 - auc: 0.8845\n",
            "Epoch 12/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1199 - tp: 11668.0938 - fp: 364.9113 - tn: 367.9177 - fn: 62.9563 - accuracy: 0.9659 - precision: 0.9697 - recall: 0.9949 - auc: 0.8822\n",
            "Epoch 13/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1225 - tp: 11631.0347 - fp: 358.1195 - tn: 390.9087 - fn: 83.8162 - accuracy: 0.9645 - precision: 0.9707 - recall: 0.9922 - auc: 0.8873\n",
            "Epoch 14/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1143 - tp: 11683.7442 - fp: 331.6478 - tn: 388.6452 - fn: 59.8419 - accuracy: 0.9683 - precision: 0.9719 - recall: 0.9951 - auc: 0.8880\n",
            "Epoch 15/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1082 - tp: 11678.9769 - fp: 334.0206 - tn: 396.3239 - fn: 54.5578 - accuracy: 0.9705 - precision: 0.9740 - recall: 0.9952 - auc: 0.8887\n",
            "Epoch 16/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1029 - tp: 11670.9280 - fp: 304.5835 - tn: 445.4807 - fn: 42.8869 - accuracy: 0.9728 - precision: 0.9748 - recall: 0.9968 - auc: 0.8958\n",
            "Epoch 17/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1043 - tp: 11635.3213 - fp: 266.9216 - tn: 467.4871 - fn: 94.1491 - accuracy: 0.9722 - precision: 0.9780 - recall: 0.9928 - auc: 0.9078\n",
            "Epoch 18/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.0988 - tp: 11691.2519 - fp: 317.9010 - tn: 403.3136 - fn: 51.4126 - accuracy: 0.9717 - precision: 0.9745 - recall: 0.9961 - auc: 0.9138\n",
            "Epoch 19/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1171 - tp: 11629.8201 - fp: 318.7905 - tn: 415.5604 - fn: 99.7082 - accuracy: 0.9665 - precision: 0.9742 - recall: 0.9906 - auc: 0.8916\n",
            "777/777 [==============================] - 7s 5ms/step - loss: 1.7922 - tp: 1457.0000 - fp: 11733.0000 - tn: 11628.0000 - fn: 15.0000 - accuracy: 0.5269 - precision: 0.1105 - recall: 0.9898 - auc: 0.8428\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_112 (LSTM)              (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_113 (LSTM)              (None, 1, 32)             29824     \n",
            "_________________________________________________________________\n",
            "dropout_84 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_114 (LSTM)              (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_85 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_115 (LSTM)              (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_86 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_116 (LSTM)              (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_87 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_117 (LSTM)              (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_88 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_118 (LSTM)              (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_89 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_119 (LSTM)              (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 275,777\n",
            "Trainable params: 275,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 26s 15ms/step - loss: 0.2489 - tp: 1468.1041 - fp: 11755.1234 - tn: 23320.8535 - fn: 752.7982 - accuracy: 0.6536 - precision: 0.1110 - recall: 0.6857 - auc: 0.7460\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.2038 - tp: 55.9614 - fp: 16.9833 - tn: 11705.4692 - fn: 685.4653 - accuracy: 0.9439 - precision: 0.7952 - recall: 0.0807 - auc: 0.7034\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1953 - tp: 80.6967 - fp: 77.8445 - tn: 11651.1632 - fn: 654.1748 - accuracy: 0.9421 - precision: 0.5346 - recall: 0.1041 - auc: 0.7025\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.2013 - tp: 64.4769 - fp: 45.9357 - tn: 11664.4550 - fn: 689.0116 - accuracy: 0.9402 - precision: 0.5784 - recall: 0.0934 - auc: 0.7258\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.2004 - tp: 85.4769 - fp: 58.8625 - tn: 11650.3997 - fn: 669.1401 - accuracy: 0.9411 - precision: 0.5678 - recall: 0.1273 - auc: 0.7043\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1911 - tp: 131.3316 - fp: 61.6748 - tn: 11667.1620 - fn: 603.7108 - accuracy: 0.9470 - precision: 0.6843 - recall: 0.1693 - auc: 0.7221\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1851 - tp: 132.9499 - fp: 40.5746 - tn: 11702.6620 - fn: 587.6928 - accuracy: 0.9496 - precision: 0.7533 - recall: 0.1846 - auc: 0.7237\n",
            "Epoch 8/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1888 - tp: 132.7455 - fp: 30.5103 - tn: 11681.9961 - fn: 618.6272 - accuracy: 0.9473 - precision: 0.7928 - recall: 0.1891 - auc: 0.7178\n",
            "Epoch 9/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1874 - tp: 96.9293 - fp: 19.9100 - tn: 11712.6324 - fn: 634.4075 - accuracy: 0.9483 - precision: 0.8225 - recall: 0.1399 - auc: 0.6667\n",
            "Epoch 10/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1857 - tp: 113.1003 - fp: 35.5990 - tn: 11688.9807 - fn: 626.1992 - accuracy: 0.9478 - precision: 0.8052 - recall: 0.1628 - auc: 0.7234\n",
            "Epoch 11/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1853 - tp: 111.3753 - fp: 48.6825 - tn: 11675.0540 - fn: 628.7674 - accuracy: 0.9453 - precision: 0.6895 - recall: 0.1448 - auc: 0.7545\n",
            "Epoch 12/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1853 - tp: 173.4409 - fp: 58.7057 - tn: 11650.2108 - fn: 581.5219 - accuracy: 0.9481 - precision: 0.7845 - recall: 0.2444 - auc: 0.7419\n",
            "Epoch 13/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1877 - tp: 150.3817 - fp: 75.0527 - tn: 11640.4062 - fn: 598.0386 - accuracy: 0.9475 - precision: 0.6801 - recall: 0.2134 - auc: 0.6912\n",
            "Epoch 14/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1925 - tp: 118.0283 - fp: 36.4666 - tn: 11693.6260 - fn: 615.7584 - accuracy: 0.9480 - precision: 0.7690 - recall: 0.1700 - auc: 0.6581\n",
            "Epoch 15/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1914 - tp: 120.2468 - fp: 49.5321 - tn: 11676.0720 - fn: 618.0283 - accuracy: 0.9457 - precision: 0.7002 - recall: 0.1626 - auc: 0.7247\n",
            "777/777 [==============================] - 7s 5ms/step - loss: 2.1933 - tp: 5631.0000 - fp: 6.0000 - tn: 1466.0000 - fn: 17730.0000 - accuracy: 0.2858 - precision: 0.9989 - recall: 0.2410 - auc: 0.7060\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_120 (LSTM)              (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_121 (LSTM)              (None, 1, 31)             28768     \n",
            "_________________________________________________________________\n",
            "dropout_90 (Dropout)         (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_122 (LSTM)              (None, 1, 31)             7812      \n",
            "_________________________________________________________________\n",
            "dropout_91 (Dropout)         (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_123 (LSTM)              (None, 1, 31)             7812      \n",
            "_________________________________________________________________\n",
            "dropout_92 (Dropout)         (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_124 (LSTM)              (None, 1, 31)             7812      \n",
            "_________________________________________________________________\n",
            "dropout_93 (Dropout)         (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_125 (LSTM)              (None, 1, 31)             7812      \n",
            "_________________________________________________________________\n",
            "dropout_94 (Dropout)         (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_126 (LSTM)              (None, 1, 31)             7812      \n",
            "_________________________________________________________________\n",
            "dropout_95 (Dropout)         (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_127 (LSTM)              (None, 31)                7812      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 271,672\n",
            "Trainable params: 271,672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 27s 15ms/step - loss: 0.2420 - tp: 17336.2751 - fp: 746.6041 - tn: 1468.0000 - fn: 17746.0000 - accuracy: 0.4868 - precision: 0.9628 - recall: 0.4740 - auc: 0.6097\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.2149 - tp: 11728.9049 - fp: 734.9743 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9409 - precision: 0.9409 - recall: 1.0000 - auc: 0.6189\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.2333 - tp: 11697.0103 - fp: 766.8689 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9365 - precision: 0.9365 - recall: 1.0000 - auc: 0.5359\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.2048 - tp: 11748.6337 - fp: 715.2455 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9433 - precision: 0.9433 - recall: 1.0000 - auc: 0.6323\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.2086 - tp: 11724.7185 - fp: 738.2622 - tn: 0.6877 - fn: 0.2108 - accuracy: 0.9397 - precision: 0.9397 - recall: 1.0000 - auc: 0.6826\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1948 - tp: 11747.3599 - fp: 716.3046 - tn: 0.1877 - fn: 0.0270 - accuracy: 0.9427 - precision: 0.9427 - recall: 1.0000 - auc: 0.7028\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.2027 - tp: 11712.8882 - fp: 708.0566 - tn: 19.9100 - fn: 23.0244 - accuracy: 0.9413 - precision: 0.9434 - recall: 0.9975 - auc: 0.6686\n",
            "Epoch 8/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1976 - tp: 11747.2969 - fp: 716.5823 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9426 - precision: 0.9426 - recall: 1.0000 - auc: 0.6997\n",
            "Epoch 9/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2036 - tp: 11693.3483 - fp: 743.7339 - tn: 13.9923 - fn: 12.8046 - accuracy: 0.9394 - precision: 0.9402 - recall: 0.9990 - auc: 0.7084\n",
            "Epoch 10/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.1959 - tp: 11726.1581 - fp: 737.0591 - tn: 0.0000e+00 - fn: 0.6620 - accuracy: 0.9406 - precision: 0.9406 - recall: 1.0000 - auc: 0.7345\n",
            "Epoch 11/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.2055 - tp: 11710.6003 - fp: 753.2789 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9391 - precision: 0.9391 - recall: 1.0000 - auc: 0.6924\n",
            "Epoch 12/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.2107 - tp: 11731.0501 - fp: 732.8290 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9419 - precision: 0.9419 - recall: 1.0000 - auc: 0.6190\n",
            "Epoch 13/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.2118 - tp: 11714.8380 - fp: 748.9923 - tn: 0.0360 - fn: 0.0129 - accuracy: 0.9400 - precision: 0.9400 - recall: 1.0000 - auc: 0.6283\n",
            "777/777 [==============================] - 7s 5ms/step - loss: 2.6329 - tp: 1472.0000 - fp: 23361.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0593 - precision: 0.0593 - recall: 1.0000 - auc: 0.6812\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_128 (LSTM)              (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_129 (LSTM)              (None, 1, 31)             28768     \n",
            "_________________________________________________________________\n",
            "dropout_96 (Dropout)         (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_130 (LSTM)              (None, 1, 31)             7812      \n",
            "_________________________________________________________________\n",
            "dropout_97 (Dropout)         (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_131 (LSTM)              (None, 1, 31)             7812      \n",
            "_________________________________________________________________\n",
            "dropout_98 (Dropout)         (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_132 (LSTM)              (None, 1, 31)             7812      \n",
            "_________________________________________________________________\n",
            "dropout_99 (Dropout)         (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_133 (LSTM)              (None, 1, 31)             7812      \n",
            "_________________________________________________________________\n",
            "dropout_100 (Dropout)        (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_134 (LSTM)              (None, 1, 31)             7812      \n",
            "_________________________________________________________________\n",
            "dropout_101 (Dropout)        (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_135 (LSTM)              (None, 31)                7812      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 271,672\n",
            "Trainable params: 271,672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 27s 16ms/step - loss: 0.2481 - tp: 1472.0000 - fp: 23373.3599 - tn: 11702.6170 - fn: 748.9023 - accuracy: 0.3298 - precision: 0.0592 - recall: 0.6885 - auc: 0.5878\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2267 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11722.4524 - fn: 741.4267 - accuracy: 0.9403 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5007\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2230 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11729.0077 - fn: 734.8715 - accuracy: 0.9416 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4983\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11710.3907 - fn: 753.4884 - accuracy: 0.9388 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4972\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2296 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11709.2622 - fn: 754.6170 - accuracy: 0.9393 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4955\n",
            "777/777 [==============================] - 8s 5ms/step - loss: 2.7140 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1472.0000 - fn: 23361.0000 - accuracy: 0.0593 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4997\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_136 (LSTM)              (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_137 (LSTM)              (None, 1, 27)             24624     \n",
            "_________________________________________________________________\n",
            "dropout_102 (Dropout)        (None, 1, 27)             0         \n",
            "_________________________________________________________________\n",
            "lstm_138 (LSTM)              (None, 1, 27)             5940      \n",
            "_________________________________________________________________\n",
            "dropout_103 (Dropout)        (None, 1, 27)             0         \n",
            "_________________________________________________________________\n",
            "lstm_139 (LSTM)              (None, 1, 27)             5940      \n",
            "_________________________________________________________________\n",
            "dropout_104 (Dropout)        (None, 1, 27)             0         \n",
            "_________________________________________________________________\n",
            "lstm_140 (LSTM)              (None, 1, 27)             5940      \n",
            "_________________________________________________________________\n",
            "dropout_105 (Dropout)        (None, 1, 27)             0         \n",
            "_________________________________________________________________\n",
            "lstm_141 (LSTM)              (None, 1, 27)             5940      \n",
            "_________________________________________________________________\n",
            "dropout_106 (Dropout)        (None, 1, 27)             0         \n",
            "_________________________________________________________________\n",
            "lstm_142 (LSTM)              (None, 1, 27)             5940      \n",
            "_________________________________________________________________\n",
            "dropout_107 (Dropout)        (None, 1, 27)             0         \n",
            "_________________________________________________________________\n",
            "lstm_143 (LSTM)              (None, 27)                5940      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 28        \n",
            "=================================================================\n",
            "Total params: 256,292\n",
            "Trainable params: 256,292\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 27s 15ms/step - loss: 0.2416 - tp: 11705.2725 - fp: 741.0913 - tn: 1473.5129 - fn: 23377.0026 - accuracy: 0.3299 - precision: 0.9401 - recall: 0.3071 - auc: 0.5079\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2132 - tp: 11728.9049 - fp: 734.9743 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9409 - precision: 0.9409 - recall: 1.0000 - auc: 0.6340\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2200 - tp: 11697.0103 - fp: 766.8689 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9365 - precision: 0.9365 - recall: 1.0000 - auc: 0.6747\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2037 - tp: 11748.6337 - fp: 715.2455 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9433 - precision: 0.9433 - recall: 1.0000 - auc: 0.6719\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2111 - tp: 11724.9293 - fp: 738.9499 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9397 - precision: 0.9397 - recall: 1.0000 - auc: 0.6839\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2018 - tp: 11747.3869 - fp: 716.4923 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9427 - precision: 0.9427 - recall: 1.0000 - auc: 0.6970\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2008 - tp: 11728.7609 - fp: 727.1388 - tn: 0.8278 - fn: 7.1517 - accuracy: 0.9407 - precision: 0.9415 - recall: 0.9991 - auc: 0.6844\n",
            "Epoch 8/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.1990 - tp: 11747.2969 - fp: 716.5823 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9426 - precision: 0.9426 - recall: 1.0000 - auc: 0.6840\n",
            "Epoch 9/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2019 - tp: 11706.1530 - fp: 757.7262 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9392 - precision: 0.9392 - recall: 1.0000 - auc: 0.7218\n",
            "Epoch 10/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2003 - tp: 11726.8201 - fp: 737.0591 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9406 - precision: 0.9406 - recall: 1.0000 - auc: 0.7075\n",
            "Epoch 11/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2082 - tp: 11710.6003 - fp: 753.2789 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9391 - precision: 0.9391 - recall: 1.0000 - auc: 0.7038\n",
            "Epoch 12/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2110 - tp: 11731.0501 - fp: 732.8290 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9419 - precision: 0.9419 - recall: 1.0000 - auc: 0.6303\n",
            "777/777 [==============================] - 7s 5ms/step - loss: 2.4134 - tp: 1472.0000 - fp: 23361.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0593 - precision: 0.0593 - recall: 1.0000 - auc: 0.7188\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_144 (LSTM)              (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_145 (LSTM)              (None, 1, 27)             24624     \n",
            "_________________________________________________________________\n",
            "dropout_108 (Dropout)        (None, 1, 27)             0         \n",
            "_________________________________________________________________\n",
            "lstm_146 (LSTM)              (None, 1, 27)             5940      \n",
            "_________________________________________________________________\n",
            "dropout_109 (Dropout)        (None, 1, 27)             0         \n",
            "_________________________________________________________________\n",
            "lstm_147 (LSTM)              (None, 1, 27)             5940      \n",
            "_________________________________________________________________\n",
            "dropout_110 (Dropout)        (None, 1, 27)             0         \n",
            "_________________________________________________________________\n",
            "lstm_148 (LSTM)              (None, 1, 27)             5940      \n",
            "_________________________________________________________________\n",
            "dropout_111 (Dropout)        (None, 1, 27)             0         \n",
            "_________________________________________________________________\n",
            "lstm_149 (LSTM)              (None, 1, 27)             5940      \n",
            "_________________________________________________________________\n",
            "dropout_112 (Dropout)        (None, 1, 27)             0         \n",
            "_________________________________________________________________\n",
            "lstm_150 (LSTM)              (None, 1, 27)             5940      \n",
            "_________________________________________________________________\n",
            "dropout_113 (Dropout)        (None, 1, 27)             0         \n",
            "_________________________________________________________________\n",
            "lstm_151 (LSTM)              (None, 27)                5940      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 28        \n",
            "=================================================================\n",
            "Total params: 256,292\n",
            "Trainable params: 256,292\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 27s 16ms/step - loss: 0.2489 - tp: 1472.0000 - fp: 23374.6645 - tn: 11701.3123 - fn: 748.9023 - accuracy: 0.3298 - precision: 0.0592 - recall: 0.6885 - auc: 0.6088\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2225 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11722.4524 - fn: 741.4267 - accuracy: 0.9403 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5947\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2202 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11729.0077 - fn: 734.8715 - accuracy: 0.9416 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5926\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2209 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11710.3907 - fn: 753.4884 - accuracy: 0.9388 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6113\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2223 - tp: 6.0386 - fp: 14.8252 - tn: 11694.4370 - fn: 748.5784 - accuracy: 0.9387 - precision: 0.2931 - recall: 0.0072 - auc: 0.5334\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2241 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11728.8368 - fn: 735.0424 - accuracy: 0.9416 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4855\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2212 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11743.2365 - fn: 720.6427 - accuracy: 0.9423 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5008\n",
            "777/777 [==============================] - 8s 5ms/step - loss: 2.6498 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1472.0000 - fn: 23361.0000 - accuracy: 0.0593 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5503\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_152 (LSTM)              (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_153 (LSTM)              (None, 1, 28)             25648     \n",
            "_________________________________________________________________\n",
            "dropout_114 (Dropout)        (None, 1, 28)             0         \n",
            "_________________________________________________________________\n",
            "lstm_154 (LSTM)              (None, 1, 28)             6384      \n",
            "_________________________________________________________________\n",
            "dropout_115 (Dropout)        (None, 1, 28)             0         \n",
            "_________________________________________________________________\n",
            "lstm_155 (LSTM)              (None, 1, 28)             6384      \n",
            "_________________________________________________________________\n",
            "dropout_116 (Dropout)        (None, 1, 28)             0         \n",
            "_________________________________________________________________\n",
            "lstm_156 (LSTM)              (None, 1, 28)             6384      \n",
            "_________________________________________________________________\n",
            "dropout_117 (Dropout)        (None, 1, 28)             0         \n",
            "_________________________________________________________________\n",
            "lstm_157 (LSTM)              (None, 1, 28)             6384      \n",
            "_________________________________________________________________\n",
            "dropout_118 (Dropout)        (None, 1, 28)             0         \n",
            "_________________________________________________________________\n",
            "lstm_158 (LSTM)              (None, 1, 28)             6384      \n",
            "_________________________________________________________________\n",
            "dropout_119 (Dropout)        (None, 1, 28)             0         \n",
            "_________________________________________________________________\n",
            "lstm_159 (LSTM)              (None, 28)                6384      \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 29        \n",
            "=================================================================\n",
            "Total params: 259,981\n",
            "Trainable params: 259,981\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 27s 15ms/step - loss: 0.2389 - tp: 11705.5591 - fp: 741.6041 - tn: 1473.0000 - fn: 23376.7159 - accuracy: 0.3299 - precision: 0.9403 - recall: 0.3071 - auc: 0.5347\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2123 - tp: 11728.9049 - fp: 734.9743 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9409 - precision: 0.9409 - recall: 1.0000 - auc: 0.6116\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2243 - tp: 11697.0103 - fp: 766.8689 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9365 - precision: 0.9365 - recall: 1.0000 - auc: 0.6322\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.1994 - tp: 11748.6337 - fp: 715.2455 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9433 - precision: 0.9433 - recall: 1.0000 - auc: 0.6924\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.2104 - tp: 11724.9293 - fp: 738.9499 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9397 - precision: 0.9397 - recall: 1.0000 - auc: 0.6307\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2001 - tp: 11745.5180 - fp: 714.1671 - tn: 2.3252 - fn: 1.8689 - accuracy: 0.9427 - precision: 0.9428 - recall: 0.9999 - auc: 0.6520\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2014 - tp: 11700.2262 - fp: 677.8406 - tn: 50.1260 - fn: 35.6864 - accuracy: 0.9431 - precision: 0.9457 - recall: 0.9968 - auc: 0.6403\n",
            "777/777 [==============================] - 7s 5ms/step - loss: 1.9922 - tp: 1472.0000 - fp: 23361.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0593 - precision: 0.0593 - recall: 1.0000 - auc: 0.6158\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_160 (LSTM)              (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_161 (LSTM)              (None, 1, 28)             25648     \n",
            "_________________________________________________________________\n",
            "dropout_120 (Dropout)        (None, 1, 28)             0         \n",
            "_________________________________________________________________\n",
            "lstm_162 (LSTM)              (None, 1, 28)             6384      \n",
            "_________________________________________________________________\n",
            "dropout_121 (Dropout)        (None, 1, 28)             0         \n",
            "_________________________________________________________________\n",
            "lstm_163 (LSTM)              (None, 1, 28)             6384      \n",
            "_________________________________________________________________\n",
            "dropout_122 (Dropout)        (None, 1, 28)             0         \n",
            "_________________________________________________________________\n",
            "lstm_164 (LSTM)              (None, 1, 28)             6384      \n",
            "_________________________________________________________________\n",
            "dropout_123 (Dropout)        (None, 1, 28)             0         \n",
            "_________________________________________________________________\n",
            "lstm_165 (LSTM)              (None, 1, 28)             6384      \n",
            "_________________________________________________________________\n",
            "dropout_124 (Dropout)        (None, 1, 28)             0         \n",
            "_________________________________________________________________\n",
            "lstm_166 (LSTM)              (None, 1, 28)             6384      \n",
            "_________________________________________________________________\n",
            "dropout_125 (Dropout)        (None, 1, 28)             0         \n",
            "_________________________________________________________________\n",
            "lstm_167 (LSTM)              (None, 28)                6384      \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 29        \n",
            "=================================================================\n",
            "Total params: 259,981\n",
            "Trainable params: 259,981\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 27s 16ms/step - loss: 0.2467 - tp: 1473.0000 - fp: 23374.0000 - tn: 11701.9769 - fn: 747.9023 - accuracy: 0.3298 - precision: 0.0593 - recall: 0.6889 - auc: 0.5633\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.2239 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11722.4524 - fn: 741.4267 - accuracy: 0.9403 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5705\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2217 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11729.0077 - fn: 734.8715 - accuracy: 0.9416 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5335\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 12s 15ms/step - loss: 0.2264 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11710.3907 - fn: 753.4884 - accuracy: 0.9388 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5547\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2157 - tp: 0.3046 - fp: 1.5373 - tn: 11707.7249 - fn: 754.3123 - accuracy: 0.9392 - precision: 0.0509 - recall: 2.4115e-04 - auc: 0.6168\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2164 - tp: 16.5643 - fp: 9.3239 - tn: 11719.5129 - fn: 718.4781 - accuracy: 0.9421 - precision: 0.5241 - recall: 0.0180 - auc: 0.5329\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2086 - tp: 38.2931 - fp: 32.9653 - tn: 11710.2712 - fn: 682.3496 - accuracy: 0.9420 - precision: 0.4904 - recall: 0.0522 - auc: 0.5898\n",
            "Epoch 8/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2176 - tp: 39.3599 - fp: 19.8021 - tn: 11692.7044 - fn: 712.0129 - accuracy: 0.9413 - precision: 0.6805 - recall: 0.0683 - auc: 0.5921\n",
            "777/777 [==============================] - 8s 5ms/step - loss: 2.8306 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1472.0000 - fn: 23361.0000 - accuracy: 0.0593 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5946\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_168 (LSTM)              (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_169 (LSTM)              (None, 1, 26)             23608     \n",
            "_________________________________________________________________\n",
            "dropout_126 (Dropout)        (None, 1, 26)             0         \n",
            "_________________________________________________________________\n",
            "lstm_170 (LSTM)              (None, 1, 26)             5512      \n",
            "_________________________________________________________________\n",
            "dropout_127 (Dropout)        (None, 1, 26)             0         \n",
            "_________________________________________________________________\n",
            "lstm_171 (LSTM)              (None, 1, 26)             5512      \n",
            "_________________________________________________________________\n",
            "dropout_128 (Dropout)        (None, 1, 26)             0         \n",
            "_________________________________________________________________\n",
            "lstm_172 (LSTM)              (None, 1, 26)             5512      \n",
            "_________________________________________________________________\n",
            "dropout_129 (Dropout)        (None, 1, 26)             0         \n",
            "_________________________________________________________________\n",
            "lstm_173 (LSTM)              (None, 1, 26)             5512      \n",
            "_________________________________________________________________\n",
            "dropout_130 (Dropout)        (None, 1, 26)             0         \n",
            "_________________________________________________________________\n",
            "lstm_174 (LSTM)              (None, 1, 26)             5512      \n",
            "_________________________________________________________________\n",
            "dropout_131 (Dropout)        (None, 1, 26)             0         \n",
            "_________________________________________________________________\n",
            "lstm_175 (LSTM)              (None, 26)                5512      \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1)                 27        \n",
            "=================================================================\n",
            "Total params: 252,707\n",
            "Trainable params: 252,707\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 27s 15ms/step - loss: 0.2440 - tp: 11709.2751 - fp: 742.6041 - tn: 1472.0000 - fn: 23373.0000 - accuracy: 0.3300 - precision: 0.9401 - recall: 0.3072 - auc: 0.5543\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2154 - tp: 11727.0103 - fp: 734.2057 - tn: 0.7686 - fn: 1.8946 - accuracy: 0.9408 - precision: 0.9409 - recall: 0.9999 - auc: 0.6276\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2204 - tp: 11697.0103 - fp: 766.4036 - tn: 0.4653 - fn: 0.0000e+00 - accuracy: 0.9365 - precision: 0.9365 - recall: 1.0000 - auc: 0.6909\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2013 - tp: 11748.6337 - fp: 715.2455 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9433 - precision: 0.9433 - recall: 1.0000 - auc: 0.6721\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2090 - tp: 11724.9293 - fp: 738.9499 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9397 - precision: 0.9397 - recall: 1.0000 - auc: 0.6628\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.1986 - tp: 11747.3869 - fp: 716.4923 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9427 - precision: 0.9427 - recall: 1.0000 - auc: 0.6688\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2032 - tp: 11735.9126 - fp: 727.9666 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9415 - precision: 0.9415 - recall: 1.0000 - auc: 0.6707\n",
            "Epoch 8/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2011 - tp: 11747.2969 - fp: 716.5823 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9426 - precision: 0.9426 - recall: 1.0000 - auc: 0.6669\n",
            "Epoch 9/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2093 - tp: 11706.1530 - fp: 757.7262 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9392 - precision: 0.9392 - recall: 1.0000 - auc: 0.6574\n",
            "Epoch 10/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2055 - tp: 11724.9794 - fp: 737.0591 - tn: 0.0000e+00 - fn: 1.8406 - accuracy: 0.9404 - precision: 0.9406 - recall: 0.9998 - auc: 0.6943\n",
            "Epoch 11/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2093 - tp: 11710.4280 - fp: 753.2789 - tn: 0.0000e+00 - fn: 0.1722 - accuracy: 0.9391 - precision: 0.9391 - recall: 1.0000 - auc: 0.6687\n",
            "Epoch 12/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2073 - tp: 11729.9383 - fp: 732.8290 - tn: 0.0000e+00 - fn: 1.1118 - accuracy: 0.9418 - precision: 0.9419 - recall: 0.9999 - auc: 0.6173\n",
            "Epoch 13/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2092 - tp: 11714.8509 - fp: 749.0283 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9400 - precision: 0.9400 - recall: 1.0000 - auc: 0.6512\n",
            "Epoch 14/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2068 - tp: 11743.2995 - fp: 720.2931 - tn: 0.0000e+00 - fn: 0.2866 - accuracy: 0.9410 - precision: 0.9410 - recall: 1.0000 - auc: 0.6646\n",
            "Epoch 15/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.1986 - tp: 11733.5347 - fp: 730.3445 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9429 - precision: 0.9429 - recall: 1.0000 - auc: 0.6769\n",
            "Epoch 16/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2031 - tp: 11712.9820 - fp: 750.0643 - tn: 0.0000e+00 - fn: 0.8329 - accuracy: 0.9397 - precision: 0.9398 - recall: 0.9999 - auc: 0.6838\n",
            "Epoch 17/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2011 - tp: 11729.4704 - fp: 734.4087 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9410 - precision: 0.9410 - recall: 1.0000 - auc: 0.6949\n",
            "Epoch 18/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.1949 - tp: 11742.6645 - fp: 721.2147 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9425 - precision: 0.9425 - recall: 1.0000 - auc: 0.7053\n",
            "Epoch 19/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2061 - tp: 11729.5283 - fp: 734.3509 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9411 - precision: 0.9411 - recall: 1.0000 - auc: 0.6890\n",
            "Epoch 20/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2065 - tp: 11725.7943 - fp: 738.0848 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9399 - precision: 0.9399 - recall: 1.0000 - auc: 0.6859\n",
            "Epoch 21/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2054 - tp: 11729.5437 - fp: 734.3355 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9417 - precision: 0.9417 - recall: 1.0000 - auc: 0.6636\n",
            "777/777 [==============================] - 7s 5ms/step - loss: 2.4221 - tp: 1472.0000 - fp: 23361.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0593 - precision: 0.0593 - recall: 1.0000 - auc: 0.6553\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_176 (LSTM)              (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_177 (LSTM)              (None, 1, 26)             23608     \n",
            "_________________________________________________________________\n",
            "dropout_132 (Dropout)        (None, 1, 26)             0         \n",
            "_________________________________________________________________\n",
            "lstm_178 (LSTM)              (None, 1, 26)             5512      \n",
            "_________________________________________________________________\n",
            "dropout_133 (Dropout)        (None, 1, 26)             0         \n",
            "_________________________________________________________________\n",
            "lstm_179 (LSTM)              (None, 1, 26)             5512      \n",
            "_________________________________________________________________\n",
            "dropout_134 (Dropout)        (None, 1, 26)             0         \n",
            "_________________________________________________________________\n",
            "lstm_180 (LSTM)              (None, 1, 26)             5512      \n",
            "_________________________________________________________________\n",
            "dropout_135 (Dropout)        (None, 1, 26)             0         \n",
            "_________________________________________________________________\n",
            "lstm_181 (LSTM)              (None, 1, 26)             5512      \n",
            "_________________________________________________________________\n",
            "dropout_136 (Dropout)        (None, 1, 26)             0         \n",
            "_________________________________________________________________\n",
            "lstm_182 (LSTM)              (None, 1, 26)             5512      \n",
            "_________________________________________________________________\n",
            "dropout_137 (Dropout)        (None, 1, 26)             0         \n",
            "_________________________________________________________________\n",
            "lstm_183 (LSTM)              (None, 26)                5512      \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1)                 27        \n",
            "=================================================================\n",
            "Total params: 252,707\n",
            "Trainable params: 252,707\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 27s 15ms/step - loss: 0.2497 - tp: 1472.0000 - fp: 23375.2609 - tn: 11700.7159 - fn: 748.9023 - accuracy: 0.3298 - precision: 0.0592 - recall: 0.6885 - auc: 0.5788\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2272 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11722.4524 - fn: 741.4267 - accuracy: 0.9403 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5027\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2243 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11729.0077 - fn: 734.8715 - accuracy: 0.9416 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4879\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2319 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11710.3907 - fn: 753.4884 - accuracy: 0.9388 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4997\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2294 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11709.2622 - fn: 754.6170 - accuracy: 0.9393 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5052\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2237 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11728.8368 - fn: 735.0424 - accuracy: 0.9416 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4838\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2214 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11743.2365 - fn: 720.6427 - accuracy: 0.9423 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4981\n",
            "Epoch 8/50\n",
            "777/777 [==============================] - 12s 16ms/step - loss: 0.2311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11712.5064 - fn: 751.3728 - accuracy: 0.9388 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5022\n",
            "777/777 [==============================] - 8s 5ms/step - loss: 2.9014 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1472.0000 - fn: 23361.0000 - accuracy: 0.0593 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_184 (LSTM)              (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_185 (LSTM)              (None, 1, 33)             30888     \n",
            "_________________________________________________________________\n",
            "dropout_138 (Dropout)        (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_186 (LSTM)              (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_139 (Dropout)        (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_187 (LSTM)              (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_140 (Dropout)        (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_188 (LSTM)              (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_141 (Dropout)        (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_189 (LSTM)              (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_142 (Dropout)        (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_190 (LSTM)              (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_143 (Dropout)        (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_191 (LSTM)              (None, 33)                8844      \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 34        \n",
            "=================================================================\n",
            "Total params: 279,986\n",
            "Trainable params: 279,986\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 27s 16ms/step - loss: 0.2427 - tp: 11702.2751 - fp: 741.6041 - tn: 1473.0000 - fn: 23380.0000 - accuracy: 0.3298 - precision: 0.9402 - recall: 0.3070 - auc: 0.5048\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2242 - tp: 11728.9049 - fp: 734.9743 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9409 - precision: 0.9409 - recall: 1.0000 - auc: 0.5215\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2349 - tp: 11694.6388 - fp: 765.6632 - tn: 1.2057 - fn: 2.3715 - accuracy: 0.9365 - precision: 0.9366 - recall: 0.9999 - auc: 0.5372\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2156 - tp: 11748.6337 - fp: 715.2455 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9433 - precision: 0.9433 - recall: 1.0000 - auc: 0.5549\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2256 - tp: 11724.3650 - fp: 737.7365 - tn: 1.2134 - fn: 0.5643 - accuracy: 0.9397 - precision: 0.9397 - recall: 1.0000 - auc: 0.5328\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2132 - tp: 11747.3869 - fp: 716.4923 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9427 - precision: 0.9427 - recall: 1.0000 - auc: 0.5622\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2181 - tp: 11735.9126 - fp: 727.9666 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.9415 - precision: 0.9415 - recall: 1.0000 - auc: 0.5634\n",
            "Epoch 8/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2112 - tp: 11746.5193 - fp: 715.3329 - tn: 1.2494 - fn: 0.7776 - accuracy: 0.9426 - precision: 0.9427 - recall: 1.0000 - auc: 0.5803\n",
            "Epoch 9/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2207 - tp: 11702.6671 - fp: 757.0746 - tn: 0.6517 - fn: 3.4859 - accuracy: 0.9390 - precision: 0.9392 - recall: 0.9997 - auc: 0.5659\n",
            "Epoch 10/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2188 - tp: 11725.8869 - fp: 736.7596 - tn: 0.2995 - fn: 0.9332 - accuracy: 0.9406 - precision: 0.9406 - recall: 0.9999 - auc: 0.5674\n",
            "Epoch 11/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2214 - tp: 11695.4730 - fp: 741.9859 - tn: 11.2931 - fn: 15.1272 - accuracy: 0.9389 - precision: 0.9400 - recall: 0.9988 - auc: 0.5718\n",
            "777/777 [==============================] - 8s 5ms/step - loss: 2.3253 - tp: 1472.0000 - fp: 23361.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0593 - precision: 0.0593 - recall: 1.0000 - auc: 0.5753\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_192 (LSTM)              (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_193 (LSTM)              (None, 1, 33)             30888     \n",
            "_________________________________________________________________\n",
            "dropout_144 (Dropout)        (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_194 (LSTM)              (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_145 (Dropout)        (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_195 (LSTM)              (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_146 (Dropout)        (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_196 (LSTM)              (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_147 (Dropout)        (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_197 (LSTM)              (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_148 (Dropout)        (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_198 (LSTM)              (None, 1, 33)             8844      \n",
            "_________________________________________________________________\n",
            "dropout_149 (Dropout)        (None, 1, 33)             0         \n",
            "_________________________________________________________________\n",
            "lstm_199 (LSTM)              (None, 33)                8844      \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1)                 34        \n",
            "=================================================================\n",
            "Total params: 279,986\n",
            "Trainable params: 279,986\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "777/777 [==============================] - 27s 16ms/step - loss: 0.2481 - tp: 1472.0000 - fp: 23377.0000 - tn: 11698.9769 - fn: 748.9023 - accuracy: 0.3297 - precision: 0.0592 - recall: 0.6885 - auc: 0.5380\n",
            "Epoch 2/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2272 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11722.4524 - fn: 741.4267 - accuracy: 0.9403 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5060\n",
            "Epoch 3/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2242 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11729.0077 - fn: 734.8715 - accuracy: 0.9416 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4856\n",
            "Epoch 4/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2318 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11710.3907 - fn: 753.4884 - accuracy: 0.9388 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4964\n",
            "Epoch 5/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2299 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11709.2622 - fn: 754.6170 - accuracy: 0.9393 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4956\n",
            "Epoch 6/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2238 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11728.8368 - fn: 735.0424 - accuracy: 0.9416 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4822\n",
            "Epoch 7/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2214 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11743.2365 - fn: 720.6427 - accuracy: 0.9423 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4945\n",
            "Epoch 8/50\n",
            "777/777 [==============================] - 13s 17ms/step - loss: 0.2311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11712.5064 - fn: 751.3728 - accuracy: 0.9388 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5036\n",
            "777/777 [==============================] - 8s 5ms/step - loss: 2.8950 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1472.0000 - fn: 23361.0000 - accuracy: 0.0593 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_200 (LSTM)              (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_201 (LSTM)              (None, 1, 32)             29824     \n",
            "_________________________________________________________________\n",
            "dropout_150 (Dropout)        (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_202 (LSTM)              (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_151 (Dropout)        (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_203 (LSTM)              (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_152 (Dropout)        (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_204 (LSTM)              (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_153 (Dropout)        (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_205 (LSTM)              (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_154 (Dropout)        (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_206 (LSTM)              (None, 1, 32)             8320      \n",
            "_________________________________________________________________\n",
            "dropout_155 (Dropout)        (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_207 (LSTM)              (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 275,777\n",
            "Trainable params: 275,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1553/1553 [==============================] - 39s 16ms/step - loss: 0.5421 - tp: 9380.5476 - fp: 3338.7349 - tn: 10532.3501 - fn: 26461.3082 - accuracy: 0.3645 - precision: 0.7168 - recall: 0.2397 - auc: 0.3367\n",
            "Epoch 2/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.3906 - tp: 10572.9524 - fp: 2294.7091 - tn: 10139.9028 - fn: 1872.3764 - accuracy: 0.8302 - precision: 0.8196 - recall: 0.8469 - auc: 0.9032\n",
            "Epoch 3/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.3319 - tp: 11103.7008 - fp: 2016.5521 - tn: 10398.1834 - fn: 1361.5045 - accuracy: 0.8631 - precision: 0.8447 - recall: 0.8920 - auc: 0.9297\n",
            "Epoch 4/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.2868 - tp: 11332.9279 - fp: 1813.7181 - tn: 10660.0965 - fn: 1073.1982 - accuracy: 0.8836 - precision: 0.8612 - recall: 0.9133 - auc: 0.9472\n",
            "Epoch 5/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.2597 - tp: 11511.6641 - fp: 1635.2233 - tn: 10772.0380 - fn: 961.0154 - accuracy: 0.8965 - precision: 0.8783 - recall: 0.9221 - auc: 0.9560\n",
            "Epoch 6/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.2453 - tp: 11663.2426 - fp: 1591.7954 - tn: 10822.1152 - fn: 802.7876 - accuracy: 0.9042 - precision: 0.8797 - recall: 0.9373 - auc: 0.9596\n",
            "Epoch 7/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.2291 - tp: 11647.8732 - fp: 1562.3597 - tn: 10949.6750 - fn: 720.0328 - accuracy: 0.9094 - precision: 0.8823 - recall: 0.9430 - auc: 0.9646\n",
            "Epoch 8/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.2308 - tp: 11684.5631 - fp: 1500.5090 - tn: 10947.8218 - fn: 747.0470 - accuracy: 0.9095 - precision: 0.8859 - recall: 0.9406 - auc: 0.9645\n",
            "Epoch 9/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.2233 - tp: 11733.9118 - fp: 1410.9389 - tn: 10989.7059 - fn: 745.3842 - accuracy: 0.9132 - precision: 0.8932 - recall: 0.9392 - auc: 0.9663\n",
            "Epoch 10/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.2209 - tp: 11763.9768 - fp: 1423.9710 - tn: 10998.6976 - fn: 693.2954 - accuracy: 0.9143 - precision: 0.8905 - recall: 0.9450 - auc: 0.9668\n",
            "Epoch 11/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.2132 - tp: 11856.9871 - fp: 1430.9221 - tn: 10978.3938 - fn: 613.6377 - accuracy: 0.9186 - precision: 0.8941 - recall: 0.9505 - auc: 0.9687\n",
            "Epoch 12/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.2097 - tp: 11735.0367 - fp: 1331.9060 - tn: 11142.5875 - fn: 670.4106 - accuracy: 0.9199 - precision: 0.8974 - recall: 0.9469 - auc: 0.9692\n",
            "Epoch 13/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.2152 - tp: 11627.5534 - fp: 1266.7819 - tn: 11164.5373 - fn: 821.0682 - accuracy: 0.9164 - precision: 0.9015 - recall: 0.9346 - auc: 0.9689\n",
            "Epoch 14/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.2133 - tp: 11817.5347 - fp: 1301.0534 - tn: 11070.4215 - fn: 690.9311 - accuracy: 0.9192 - precision: 0.9014 - recall: 0.9427 - auc: 0.9681\n",
            "Epoch 15/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.2004 - tp: 11800.2947 - fp: 1293.0019 - tn: 11182.6969 - fn: 603.9472 - accuracy: 0.9233 - precision: 0.9009 - recall: 0.9506 - auc: 0.9716\n",
            "Epoch 16/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.2031 - tp: 11806.9730 - fp: 1276.3063 - tn: 11176.7896 - fn: 619.8719 - accuracy: 0.9232 - precision: 0.9016 - recall: 0.9497 - auc: 0.9708\n",
            "Epoch 17/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.2014 - tp: 11813.7214 - fp: 1241.0837 - tn: 11148.1647 - fn: 676.9710 - accuracy: 0.9231 - precision: 0.9058 - recall: 0.9457 - auc: 0.9713\n",
            "Epoch 18/50\n",
            "1553/1553 [==============================] - 25s 16ms/step - loss: 0.1954 - tp: 11837.5122 - fp: 1189.5180 - tn: 11246.9595 - fn: 605.9511 - accuracy: 0.9285 - precision: 0.9098 - recall: 0.9516 - auc: 0.9720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=2, error_score='raise-deprecating',\n",
              "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fcdbeb152d0>,\n",
              "                   iid='warn', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'learning_rate': [0.01, 0.02],\n",
              "                                        'n_neurons': array([25, 26, 27, 28, 29, 30, 31, 32, 33, 34])},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEfnLbv16RBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d1bf8a2-cf70-4008-8a7e-033cfe68b49f"
      },
      "source": [
        "# So what is the best parameters that were found???\n",
        "#RandomSearch results for oversampled model {'n_neurons': 54, 'learning_rate': 0.01}\n",
        "#RandomSearch results for non-oversampled model {'n_neurons': 51, 'learning_rate': 0.02}\n",
        "#RNN network {'n_neurons': 32, 'learning_rate': 0.01}\n",
        "print(rnd_search_cv.best_params_)\n",
        "print(rnd_search_cv.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 32, 'learning_rate': 0.01}\n",
            "0.40635445713996887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3zViPPeyEqp"
      },
      "source": [
        "model_class_nonoversampled = build_model_basic(n_neurons=51, learning_rate= 0.02)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7wiXP-ucOef",
        "outputId": "7e18c875-b589-4fe4-b843-dc0657f15640"
      },
      "source": [
        "#RNN training without data augmentation\n",
        "model_rnn_func = build_RNN_model(n_neurons = 31, learning_rate= 0.01)\n",
        "\n",
        "history_rnn_class = model_rnn_func.fit(train_features_rnn, train_labels,epochs = 20, validation_data = (val_features_rnn, val_labels))\n",
        "\n",
        "#Prediction\n",
        "test_df_rnn = test_df.to_numpy().reshape(test_df.shape[0],  1,test_df.shape[1])\n",
        "y_predicted_rnn = model_rnn_func.predict(test_df_rnn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_229 (LSTM)              (None, 1, 200)            196000    \n",
            "_________________________________________________________________\n",
            "lstm_230 (LSTM)              (None, 1, 31)             28768     \n",
            "_________________________________________________________________\n",
            "dropout_174 (Dropout)        (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_231 (LSTM)              (None, 1, 31)             7812      \n",
            "_________________________________________________________________\n",
            "dropout_175 (Dropout)        (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_232 (LSTM)              (None, 1, 31)             7812      \n",
            "_________________________________________________________________\n",
            "dropout_176 (Dropout)        (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_233 (LSTM)              (None, 1, 31)             7812      \n",
            "_________________________________________________________________\n",
            "dropout_177 (Dropout)        (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_234 (LSTM)              (None, 1, 31)             7812      \n",
            "_________________________________________________________________\n",
            "dropout_178 (Dropout)        (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_235 (LSTM)              (None, 1, 31)             7812      \n",
            "_________________________________________________________________\n",
            "dropout_179 (Dropout)        (None, 1, 31)             0         \n",
            "_________________________________________________________________\n",
            "lstm_236 (LSTM)              (None, 31)                7812      \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 271,672\n",
            "Trainable params: 271,672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "825/825 [==============================] - 25s 16ms/step - loss: 0.2406 - tp: 256.0000 - fp: 837.0000 - tn: 17839.9697 - fn: 898.9915 - accuracy: 0.9065 - precision: 0.2342 - recall: 0.2680 - auc: 0.6821 - val_loss: 0.2194 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 6205.0000 - val_fn: 395.0000 - val_accuracy: 0.9402 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6271\n",
            "Epoch 2/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.2050 - tp: 33.7107 - fp: 18.9443 - tn: 12440.5823 - fn: 738.7240 - accuracy: 0.9426 - precision: 0.4355 - recall: 0.0271 - auc: 0.6571 - val_loss: 0.2144 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 6205.0000 - val_fn: 395.0000 - val_accuracy: 0.9402 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6396\n",
            "Epoch 3/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.2019 - tp: 16.1828 - fp: 7.2240 - tn: 12444.5751 - fn: 763.9794 - accuracy: 0.9422 - precision: 0.2744 - recall: 0.0119 - auc: 0.6520 - val_loss: 0.2021 - val_tp: 27.0000 - val_fp: 4.0000 - val_tn: 6201.0000 - val_fn: 368.0000 - val_accuracy: 0.9436 - val_precision: 0.8710 - val_recall: 0.0684 - val_auc: 0.6903\n",
            "Epoch 4/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.2014 - tp: 124.0436 - fp: 74.2809 - tn: 12357.7058 - fn: 675.9310 - accuracy: 0.9427 - precision: 0.6188 - recall: 0.1534 - auc: 0.6806 - val_loss: 0.2039 - val_tp: 47.0000 - val_fp: 4.0000 - val_tn: 6201.0000 - val_fn: 348.0000 - val_accuracy: 0.9467 - val_precision: 0.9216 - val_recall: 0.1190 - val_auc: 0.6646\n",
            "Epoch 5/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.1924 - tp: 97.8160 - fp: 69.3814 - tn: 12385.9455 - fn: 678.8184 - accuracy: 0.9449 - precision: 0.5736 - recall: 0.1323 - auc: 0.6807 - val_loss: 0.2104 - val_tp: 22.0000 - val_fp: 2.0000 - val_tn: 6203.0000 - val_fn: 373.0000 - val_accuracy: 0.9432 - val_precision: 0.9167 - val_recall: 0.0557 - val_auc: 0.5822\n",
            "Epoch 6/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.2095 - tp: 78.4007 - fp: 51.9395 - tn: 12389.8136 - fn: 711.8075 - accuracy: 0.9423 - precision: 0.6211 - recall: 0.1116 - auc: 0.6189 - val_loss: 0.2121 - val_tp: 32.0000 - val_fp: 14.0000 - val_tn: 6191.0000 - val_fn: 363.0000 - val_accuracy: 0.9429 - val_precision: 0.6957 - val_recall: 0.0810 - val_auc: 0.6131\n",
            "Epoch 7/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.2063 - tp: 71.0811 - fp: 45.7724 - tn: 12381.4673 - fn: 733.6404 - accuracy: 0.9415 - precision: 0.6265 - recall: 0.0993 - auc: 0.6493 - val_loss: 0.2123 - val_tp: 10.0000 - val_fp: 0.0000e+00 - val_tn: 6205.0000 - val_fn: 385.0000 - val_accuracy: 0.9417 - val_precision: 1.0000 - val_recall: 0.0253 - val_auc: 0.5827\n",
            "Epoch 8/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.2076 - tp: 63.6683 - fp: 20.2615 - tn: 12441.1913 - fn: 706.8402 - accuracy: 0.9451 - precision: 0.7303 - recall: 0.0752 - auc: 0.5617 - val_loss: 0.2048 - val_tp: 70.0000 - val_fp: 28.0000 - val_tn: 6177.0000 - val_fn: 325.0000 - val_accuracy: 0.9465 - val_precision: 0.7143 - val_recall: 0.1772 - val_auc: 0.5939\n",
            "Epoch 9/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.2101 - tp: 95.3596 - fp: 26.0884 - tn: 12419.3910 - fn: 691.1223 - accuracy: 0.9451 - precision: 0.7602 - recall: 0.1191 - auc: 0.5641 - val_loss: 0.2129 - val_tp: 27.0000 - val_fp: 2.0000 - val_tn: 6203.0000 - val_fn: 368.0000 - val_accuracy: 0.9439 - val_precision: 0.9310 - val_recall: 0.0684 - val_auc: 0.5649\n",
            "Epoch 10/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.2007 - tp: 68.4915 - fp: 50.9358 - tn: 12413.0581 - fn: 699.4758 - accuracy: 0.9452 - precision: 0.5909 - recall: 0.0899 - auc: 0.6087 - val_loss: 0.2036 - val_tp: 57.0000 - val_fp: 24.0000 - val_tn: 6181.0000 - val_fn: 338.0000 - val_accuracy: 0.9452 - val_precision: 0.7037 - val_recall: 0.1443 - val_auc: 0.6257\n",
            "Epoch 11/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.1960 - tp: 126.9891 - fp: 64.4370 - tn: 12385.0109 - fn: 655.5242 - accuracy: 0.9451 - precision: 0.6326 - recall: 0.1511 - auc: 0.6541 - val_loss: 0.2137 - val_tp: 37.0000 - val_fp: 52.0000 - val_tn: 6153.0000 - val_fn: 358.0000 - val_accuracy: 0.9379 - val_precision: 0.4157 - val_recall: 0.0937 - val_auc: 0.6364\n",
            "Epoch 12/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.2090 - tp: 42.6186 - fp: 27.2700 - tn: 12410.5714 - fn: 751.5012 - accuracy: 0.9406 - precision: 0.5745 - recall: 0.0646 - auc: 0.6539 - val_loss: 0.2032 - val_tp: 29.0000 - val_fp: 12.0000 - val_tn: 6193.0000 - val_fn: 366.0000 - val_accuracy: 0.9427 - val_precision: 0.7073 - val_recall: 0.0734 - val_auc: 0.6272\n",
            "Epoch 13/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.1953 - tp: 76.8814 - fp: 39.0194 - tn: 12414.6695 - fn: 701.3910 - accuracy: 0.9451 - precision: 0.6351 - recall: 0.0916 - auc: 0.6521 - val_loss: 0.2047 - val_tp: 67.0000 - val_fp: 46.0000 - val_tn: 6159.0000 - val_fn: 328.0000 - val_accuracy: 0.9433 - val_precision: 0.5929 - val_recall: 0.1696 - val_auc: 0.6405\n",
            "Epoch 14/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.1951 - tp: 104.8874 - fp: 55.5133 - tn: 12396.2942 - fn: 675.2663 - accuracy: 0.9449 - precision: 0.6791 - recall: 0.1439 - auc: 0.6690 - val_loss: 0.2035 - val_tp: 43.0000 - val_fp: 6.0000 - val_tn: 6199.0000 - val_fn: 352.0000 - val_accuracy: 0.9458 - val_precision: 0.8776 - val_recall: 0.1089 - val_auc: 0.6402\n",
            "Epoch 15/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.2018 - tp: 94.0121 - fp: 41.2373 - tn: 12398.6404 - fn: 698.0714 - accuracy: 0.9435 - precision: 0.6671 - recall: 0.1126 - auc: 0.6576 - val_loss: 0.2127 - val_tp: 34.0000 - val_fp: 3.0000 - val_tn: 6202.0000 - val_fn: 361.0000 - val_accuracy: 0.9448 - val_precision: 0.9189 - val_recall: 0.0861 - val_auc: 0.5725\n",
            "Epoch 16/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.1983 - tp: 97.3765 - fp: 41.9274 - tn: 12411.9613 - fn: 680.6961 - accuracy: 0.9462 - precision: 0.7315 - recall: 0.1302 - auc: 0.6175 - val_loss: 0.1985 - val_tp: 28.0000 - val_fp: 1.0000 - val_tn: 6204.0000 - val_fn: 367.0000 - val_accuracy: 0.9442 - val_precision: 0.9655 - val_recall: 0.0709 - val_auc: 0.6359\n",
            "Epoch 17/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.1906 - tp: 67.2131 - fp: 32.8378 - tn: 12422.8015 - fn: 709.1090 - accuracy: 0.9445 - precision: 0.6928 - recall: 0.0893 - auc: 0.6699 - val_loss: 0.1968 - val_tp: 24.0000 - val_fp: 1.0000 - val_tn: 6204.0000 - val_fn: 371.0000 - val_accuracy: 0.9436 - val_precision: 0.9600 - val_recall: 0.0608 - val_auc: 0.6371\n",
            "Epoch 18/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.1920 - tp: 101.7724 - fp: 48.2264 - tn: 12401.6017 - fn: 680.3608 - accuracy: 0.9445 - precision: 0.6838 - recall: 0.1230 - auc: 0.6528 - val_loss: 0.1961 - val_tp: 86.0000 - val_fp: 30.0000 - val_tn: 6175.0000 - val_fn: 309.0000 - val_accuracy: 0.9486 - val_precision: 0.7414 - val_recall: 0.2177 - val_auc: 0.6213\n",
            "Epoch 19/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.1928 - tp: 113.7191 - fp: 81.7518 - tn: 12355.6852 - fn: 680.8051 - accuracy: 0.9442 - precision: 0.5906 - recall: 0.1832 - auc: 0.6664 - val_loss: 0.2034 - val_tp: 12.0000 - val_fp: 0.0000e+00 - val_tn: 6205.0000 - val_fn: 383.0000 - val_accuracy: 0.9420 - val_precision: 1.0000 - val_recall: 0.0304 - val_auc: 0.6350\n",
            "Epoch 20/20\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.2007 - tp: 83.5678 - fp: 34.7845 - tn: 12395.0581 - fn: 718.5508 - accuracy: 0.9429 - precision: 0.7230 - recall: 0.1043 - auc: 0.6573 - val_loss: 0.2019 - val_tp: 58.0000 - val_fp: 39.0000 - val_tn: 6166.0000 - val_fn: 337.0000 - val_accuracy: 0.9430 - val_precision: 0.5979 - val_recall: 0.1468 - val_auc: 0.6216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulvOkVwvx2Li",
        "outputId": "81f3dd3d-5f7d-4901-e3e2-748eccf3a715"
      },
      "source": [
        "#RNN training with data augmentation\n",
        "model_rnn_func_oversamp = RNNModel(n_neurons = 31)\n",
        "model_rnn_func_oversamp.compile(optimizer = keras.optimizers.Adam(lr=0.01),\n",
        "                loss = keras.losses.BinaryCrossentropy(),\n",
        "                metrics = metrics)\n",
        "\n",
        "history_rnn_class = model_rnn_func_oversamp.fit(train_features_oversampled_rnn, train_labels_oversampled,epochs = 20, validation_data = (val_features_rnn, val_labels))\n",
        "\n",
        "#Prediction\n",
        "test_df_rnn = test_df.to_numpy().reshape(test_df.shape[0],  1,test_df.shape[1])\n",
        "y_predicted_rnn_oversampl = model_rnn_func_oversamp.predict(test_df_rnn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1553/1553 [==============================] - 32s 12ms/step - loss: 0.5278 - tp: 9545.2806 - fp: 3162.6094 - tn: 15441.4755 - fn: 3330.5753 - accuracy: 0.8018 - precision: 0.7368 - recall: 0.7051 - auc: 0.8711 - val_loss: 0.4094 - val_tp: 266.0000 - val_fp: 1170.0000 - val_tn: 5035.0000 - val_fn: 129.0000 - val_accuracy: 0.8032 - val_precision: 0.1852 - val_recall: 0.6734 - val_auc: 0.8059\n",
            "Epoch 2/20\n",
            "1553/1553 [==============================] - 15s 10ms/step - loss: 0.4056 - tp: 10375.8468 - fp: 2482.6480 - tn: 9951.9640 - fn: 2069.4820 - accuracy: 0.8152 - precision: 0.8047 - recall: 0.8325 - auc: 0.8963 - val_loss: 0.4328 - val_tp: 270.0000 - val_fp: 1377.0000 - val_tn: 4828.0000 - val_fn: 125.0000 - val_accuracy: 0.7724 - val_precision: 0.1639 - val_recall: 0.6835 - val_auc: 0.7962\n",
            "Epoch 3/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.3694 - tp: 10666.5148 - fp: 2299.1313 - tn: 10115.6042 - fn: 1798.6905 - accuracy: 0.8342 - precision: 0.8194 - recall: 0.8605 - auc: 0.9142 - val_loss: 0.4178 - val_tp: 261.0000 - val_fp: 1221.0000 - val_tn: 4984.0000 - val_fn: 134.0000 - val_accuracy: 0.7947 - val_precision: 0.1761 - val_recall: 0.6608 - val_auc: 0.7961\n",
            "Epoch 4/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.3461 - tp: 10810.1757 - fp: 2185.8539 - tn: 10287.9607 - fn: 1595.9505 - accuracy: 0.8483 - precision: 0.8302 - recall: 0.8738 - auc: 0.9249 - val_loss: 0.4076 - val_tp: 267.0000 - val_fp: 1262.0000 - val_tn: 4943.0000 - val_fn: 128.0000 - val_accuracy: 0.7894 - val_precision: 0.1746 - val_recall: 0.6759 - val_auc: 0.7986\n",
            "Epoch 5/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.3358 - tp: 10959.9646 - fp: 2162.7677 - tn: 10244.4936 - fn: 1512.7149 - accuracy: 0.8512 - precision: 0.8339 - recall: 0.8797 - auc: 0.9287 - val_loss: 0.3743 - val_tp: 240.0000 - val_fp: 910.0000 - val_tn: 5295.0000 - val_fn: 155.0000 - val_accuracy: 0.8386 - val_precision: 0.2087 - val_recall: 0.6076 - val_auc: 0.7934\n",
            "Epoch 6/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.3179 - tp: 11113.8629 - fp: 2082.7664 - tn: 10331.1441 - fn: 1352.1673 - accuracy: 0.8623 - precision: 0.8424 - recall: 0.8926 - auc: 0.9365 - val_loss: 0.3815 - val_tp: 245.0000 - val_fp: 924.0000 - val_tn: 5281.0000 - val_fn: 150.0000 - val_accuracy: 0.8373 - val_precision: 0.2096 - val_recall: 0.6203 - val_auc: 0.7979\n",
            "Epoch 7/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.3116 - tp: 10999.1564 - fp: 2001.6847 - tn: 10510.3501 - fn: 1368.7497 - accuracy: 0.8660 - precision: 0.8481 - recall: 0.8887 - auc: 0.9387 - val_loss: 0.3918 - val_tp: 254.0000 - val_fp: 1085.0000 - val_tn: 5120.0000 - val_fn: 141.0000 - val_accuracy: 0.8142 - val_precision: 0.1897 - val_recall: 0.6430 - val_auc: 0.8008\n",
            "Epoch 8/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.3059 - tp: 11255.9234 - fp: 2054.9730 - tn: 10393.3578 - fn: 1175.6866 - accuracy: 0.8709 - precision: 0.8444 - recall: 0.9102 - auc: 0.9407 - val_loss: 0.3727 - val_tp: 250.0000 - val_fp: 998.0000 - val_tn: 5207.0000 - val_fn: 145.0000 - val_accuracy: 0.8268 - val_precision: 0.2003 - val_recall: 0.6329 - val_auc: 0.7996\n",
            "Epoch 9/20\n",
            "1553/1553 [==============================] - 15s 10ms/step - loss: 0.3025 - tp: 11288.2754 - fp: 2055.3777 - tn: 10345.2671 - fn: 1191.0206 - accuracy: 0.8701 - precision: 0.8486 - recall: 0.9020 - auc: 0.9423 - val_loss: 0.4011 - val_tp: 252.0000 - val_fp: 1080.0000 - val_tn: 5125.0000 - val_fn: 143.0000 - val_accuracy: 0.8147 - val_precision: 0.1892 - val_recall: 0.6380 - val_auc: 0.7948\n",
            "Epoch 10/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.2954 - tp: 11340.5553 - fp: 2010.4794 - tn: 10412.1892 - fn: 1116.7169 - accuracy: 0.8741 - precision: 0.8488 - recall: 0.9110 - auc: 0.9447 - val_loss: 0.3780 - val_tp: 249.0000 - val_fp: 972.0000 - val_tn: 5233.0000 - val_fn: 146.0000 - val_accuracy: 0.8306 - val_precision: 0.2039 - val_recall: 0.6304 - val_auc: 0.8024\n",
            "Epoch 11/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.2958 - tp: 11329.4646 - fp: 1964.5656 - tn: 10444.7503 - fn: 1141.1602 - accuracy: 0.8760 - precision: 0.8527 - recall: 0.9104 - auc: 0.9433 - val_loss: 0.3861 - val_tp: 259.0000 - val_fp: 1006.0000 - val_tn: 5199.0000 - val_fn: 136.0000 - val_accuracy: 0.8270 - val_precision: 0.2047 - val_recall: 0.6557 - val_auc: 0.8046\n",
            "Epoch 12/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.2889 - tp: 11239.1737 - fp: 1849.3526 - tn: 10625.1409 - fn: 1166.2735 - accuracy: 0.8776 - precision: 0.8582 - recall: 0.9024 - auc: 0.9467 - val_loss: 0.3717 - val_tp: 256.0000 - val_fp: 1002.0000 - val_tn: 5203.0000 - val_fn: 139.0000 - val_accuracy: 0.8271 - val_precision: 0.2035 - val_recall: 0.6481 - val_auc: 0.8023\n",
            "Epoch 13/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.2845 - tp: 11407.2342 - fp: 1920.1589 - tn: 10511.1602 - fn: 1041.3874 - accuracy: 0.8809 - precision: 0.8548 - recall: 0.9172 - auc: 0.9481 - val_loss: 0.3612 - val_tp: 243.0000 - val_fp: 837.0000 - val_tn: 5368.0000 - val_fn: 152.0000 - val_accuracy: 0.8502 - val_precision: 0.2250 - val_recall: 0.6152 - val_auc: 0.8054\n",
            "Epoch 14/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.2768 - tp: 11440.7735 - fp: 1838.6088 - tn: 10532.8662 - fn: 1067.6924 - accuracy: 0.8838 - precision: 0.8632 - recall: 0.9141 - auc: 0.9510 - val_loss: 0.3439 - val_tp: 246.0000 - val_fp: 872.0000 - val_tn: 5333.0000 - val_fn: 149.0000 - val_accuracy: 0.8453 - val_precision: 0.2200 - val_recall: 0.6228 - val_auc: 0.8073\n",
            "Epoch 15/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.2705 - tp: 11372.2252 - fp: 1821.3160 - tn: 10654.3829 - fn: 1032.0167 - accuracy: 0.8867 - precision: 0.8626 - recall: 0.9189 - auc: 0.9534 - val_loss: 0.3463 - val_tp: 255.0000 - val_fp: 918.0000 - val_tn: 5287.0000 - val_fn: 140.0000 - val_accuracy: 0.8397 - val_precision: 0.2174 - val_recall: 0.6456 - val_auc: 0.8146\n",
            "Epoch 16/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.2767 - tp: 11331.4736 - fp: 1817.2793 - tn: 10635.8166 - fn: 1095.3713 - accuracy: 0.8829 - precision: 0.8622 - recall: 0.9108 - auc: 0.9513 - val_loss: 0.3492 - val_tp: 235.0000 - val_fp: 823.0000 - val_tn: 5382.0000 - val_fn: 160.0000 - val_accuracy: 0.8511 - val_precision: 0.2221 - val_recall: 0.5949 - val_auc: 0.8077\n",
            "Epoch 17/20\n",
            "1553/1553 [==============================] - 16s 11ms/step - loss: 0.2688 - tp: 11503.5734 - fp: 1863.8874 - tn: 10525.3610 - fn: 987.1190 - accuracy: 0.8856 - precision: 0.8598 - recall: 0.9234 - auc: 0.9536 - val_loss: 0.3506 - val_tp: 244.0000 - val_fp: 930.0000 - val_tn: 5275.0000 - val_fn: 151.0000 - val_accuracy: 0.8362 - val_precision: 0.2078 - val_recall: 0.6177 - val_auc: 0.8060\n",
            "Epoch 18/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.2646 - tp: 11420.0959 - fp: 1749.0019 - tn: 10687.4755 - fn: 1023.3674 - accuracy: 0.8896 - precision: 0.8673 - recall: 0.9202 - auc: 0.9550 - val_loss: 0.3633 - val_tp: 254.0000 - val_fp: 995.0000 - val_tn: 5210.0000 - val_fn: 141.0000 - val_accuracy: 0.8279 - val_precision: 0.2034 - val_recall: 0.6430 - val_auc: 0.8036\n",
            "Epoch 19/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.2620 - tp: 11537.6564 - fp: 1732.8256 - tn: 10690.3726 - fn: 919.0862 - accuracy: 0.8944 - precision: 0.8690 - recall: 0.9288 - auc: 0.9553 - val_loss: 0.3627 - val_tp: 236.0000 - val_fp: 799.0000 - val_tn: 5406.0000 - val_fn: 159.0000 - val_accuracy: 0.8548 - val_precision: 0.2280 - val_recall: 0.5975 - val_auc: 0.8030\n",
            "Epoch 20/20\n",
            "1553/1553 [==============================] - 16s 10ms/step - loss: 0.2660 - tp: 11309.5972 - fp: 1647.7523 - tn: 10816.3945 - fn: 1106.1969 - accuracy: 0.8901 - precision: 0.8751 - recall: 0.9099 - auc: 0.9545 - val_loss: 0.3598 - val_tp: 254.0000 - val_fp: 824.0000 - val_tn: 5381.0000 - val_fn: 141.0000 - val_accuracy: 0.8538 - val_precision: 0.2356 - val_recall: 0.6430 - val_auc: 0.8058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuMqxuSwUIFi"
      },
      "source": [
        "#Transforming the predictions to boolean output\n",
        "y_pred_bool = np.where(y_predicted_gbc > 0.5, 1, 0)\n",
        "y_pred_bool\n",
        "\n",
        "#Generate the output file for the submission\n",
        "pd.DataFrame(y_pred_bool).set_index(x_test_Id).rename(columns={0:'psrel'}).to_csv('gbc_prediction_oversampl.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}